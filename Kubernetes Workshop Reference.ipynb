{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* setting up a generic Kubernetes system\n",
    "* deploying Laravel onto it using Helm charts (versionable infrastructure description), with Postgres, Redis and workers\n",
    "* employing a Gitlab repository for CI/CD for building container images\n",
    "* managing per-deployment configuration and environment variables\n",
    "* process health, logging and scaling\n",
    "* using the artisan CLI tool for scheduled and one-off jobs on the cluster (as time permits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "export GIT_COMMITTER_NAME=$JUPYTERHUB_USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyJhbGciOiJSUzI1NiIsImtpZCI6IjQ5ZDh0N1FTVy03S2FkVTJxZGY1cmFwRlpYaVhtTUZlVEZueTR2MVA1TkUifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJhZG1pbmlzdHJhdG9yIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6Imp1cHl0ZXItdXNlci10b2tlbi1qd2s1NiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJqdXB5dGVyLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwZGE5OTc1My0zYTUyLTQyYjgtOTc4ZC01ODg5ZDU1ZTViN2YiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6YWRtaW5pc3RyYXRvcjpqdXB5dGVyLXVzZXIifQ.XcxCm_YqeAfRqTSJZm1cxoZDhDpUueNBCh11PHgEbLcHSeIMMhFAWW04mLLSaAzXbhTyL4FkDsE41NZZ5ZG01AEUECxklk_MsCiKGtLcb0AAy8DdfJJf9mYZd4wofGX6KfOz4yqdxTaSkxUz3xfFM0Plh4e92s0PnU5glAPNY6XmDkodyQMIr-RGsVe4cAdoBckiquQoe9T49TWfcrLWRSYr59mm1KNpWqe0CcAh7F8RQPNMrhjHI9Xqdj_n-CqSWVqpjJyBkLK0EKpN5URBMhL4S64idvtTtllS7o7pB64rChjxEs4iqRlE4R9BDDcbdfdFGYjNOYUxAs9dGj4jtA\n"
     ]
    }
   ],
   "source": [
    "cd ~/kubernetes-scotlandphp\n",
    "./setup_account.sh\n",
    "chmod go-r ~/.kube/config\n",
    "export USER=$GIT_COMMITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Workshop\n",
    "\n",
    "With Phil Weir\n",
    "(the Belfast guy who is somewhere near this projector, hopefully)\n",
    "\n",
    "* Structure of course\n",
    "* Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic notebook instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Shift+Enter or Ctrl+Enter to execute a \"cell\" (each one of these rows)\n",
    "* Those with [ ] in the left gutter are executable - the others are informational\n",
    "* Up/Down arrows keys are the easiest way to navigate the notebook\n",
    "* If you select a cell (click to the left, outside the text area), the 'b' key will give you a new executable box below\n",
    "* If you accidentally edit an informational cell - it will switch to markdown - Ctrl+Enter will exit edit-mode\n",
    "* If a step hangs, with a [ * ] on the left, you may need to click the recycle button in the toolbar (if you have any other issues afterwards, re-run the cell at the top, to set environment variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Kubernetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is Kuernetes\n",
    "    * Back in the day, if you wanted to run programs on a bunch of servers you had to log in and out of them all manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How is this relevant to Python?\n",
    "  * Scalable\n",
    "  * Systematic\n",
    "  * Within control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why Kubernetes over alternatives?\n",
    "  * Other container orchestrators\n",
    "    * Popularity and backing\n",
    "    * Good balance of simplicity and complexity\n",
    "  * IaaS/PaaS\n",
    "    * Doesn't tie you to a single provider\n",
    "    * Can be run off-cloud\n",
    "    * Can be run on a dev machine\n",
    "    * Abstracts and automates the provider-specific bits (mostly)\n",
    "    * Separates out hardware from application infrastructure (containers vs servers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Brief (re)introduction to Docker\n",
    "  * If you aren't already familiar with it, you can think of a docker _container_ as a VM that shares a kernel with the host\n",
    "    * ...but don't as that loses key important differences\n",
    "  * Recommended practice is to have one process per container\n",
    "    * containers are very memory light compared to VMs, so this is much less wasteful than it may sound\n",
    "    * this provides encapsulation and makes scaling easier\n",
    "  * `docker-compose` is an _extremely_ handy tool that takes a short, app-specific _docker-compose.yml_ file as input and spins up a multi-container environment with all the expected dependencies and links\n",
    "    * you can keep the `docker-compose.yml` file in the repo with your app\n",
    "    * between docker and docker-compose, you can provide a rough alternative to VirtualBox and Vagrant developer flow (although those do not map directly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cloud\n",
    "  * GKE: gcloud\n",
    "  * AWS: EKS\n",
    "  * Azure: AKS\n",
    "  * IBM: IKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manually (kubeadm / Kubernetes the Hard Way --->)\n",
    "  * kops\n",
    "  * kubeadm\n",
    "  * [Kubernetes the Hard Way](https://github.com/kelseyhightower/kubernetes-the-hard-way)\n",
    "  * For more information, see https://kubernetes.io/docs/setup/scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Minikube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.34.1\n"
     ]
    }
   ],
   "source": [
    "git version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n",
      "Client Version: version.Info{Major:\"1\", Minor:\"26\", GitVersion:\"v1.26.0\", GitCommit:\"b46a3f887ca979b1a5d14fd39cb1af43e7e5d12d\", GitTreeState:\"clean\", BuildDate:\"2022-12-08T19:58:30Z\", GoVersion:\"go1.19.4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
      "Kustomize Version: v4.5.7\n",
      "Server Version: version.Info{Major:\"1\", Minor:\"23\", GitVersion:\"v1.23.14-gke.1800\", GitCommit:\"1eab5b8da4acab130c72aea21eb7ed3e96523ca2\", GitTreeState:\"clean\", BuildDate:\"2022-12-07T09:32:46Z\", GoVersion:\"go1.17.13b7\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
      "WARNING: version difference between client (1.26) and server (1.23) exceeds the supported minor version skew of +/-1\n"
     ]
    }
   ],
   "source": [
    "kubectl version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, I will talk a little bit about basic Kubernetes tools and concepts, then we can start building up practical steps..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language of Kubernetes communication is JSON, under the hood, but generally the tooling lets you talk to it in YAML, which is actually a (much more readable) superset. Instead of\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"apiVersion\": \"v1\",\n",
    "    \"type\": \"Pod\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"hi-pod\"\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "we can write\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "type: Pod\n",
    "metadata:\n",
    "    name: \"hi-pod\"\n",
    "```\n",
    "\n",
    "We can build up all our Kubernetes objects on the cluster by sending declarative YAML files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Just a webserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to interact with a Kubernetes cluster is the `kubectl` tool. It's preinstalled here, but you can download it yourself locally. The configuration files are called `kubeconfig` files, and the default one lives at `~/.kube/config` on Mac/*nix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*nginx* is an extremely popular webserver. We can run it on Kubernetes with no further information -- this is the equivalent of logging into a Linux server and setting up Apache (or, indeed, nginx), but in one handy line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/mynginx created\n"
     ]
    }
   ],
   "source": [
    "kubectl create deployment mynginx --image=nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _deployment_ is essentially a single application (perhaps running many times). It is normally one or more replicas of a specific process (in this case nginx), maybe with some helper process or some start-up/shutdown actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "mynginx                                                 1/1     1            1           17s\n",
      "python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           60m\n"
     ]
    }
   ],
   "source": [
    "kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run two identical instances of nginx, by scaling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/mynginx scaled\n",
      "NAME                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "mynginx                                                 1/2     2            1           21s\n",
      "python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           61m\n"
     ]
    }
   ],
   "source": [
    "kubectl scale deployment mynginx --replicas=2\n",
    "kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for us to interact with nginx we have to encounter another concept: _services_ . Commonly, we often think of a process and the service it provides as essentially equivalent - however, modern \"orchestration\" tools help decouple the idea of an advertised service (_services_) and the processes backing them up (_deployments_).\n",
    "\n",
    "This means that we can link up different tools with them only knowing each others' *services* - Kubernetes will route requests through to the deployed processes behind the scenes. If we have multiple processes running, it applies simple load balancing (\"Round Robin\" by default, passing one task/request to each processes in turn as they come in). For example, there could be 100 nginx processes spread over a dozen VMs and any internal or external request just asks for the nginx service and magically gets a reply.\n",
    "\n",
    "We created a deployment, but we still need to create that service... as with `create` for deployments, there is a command to attach a service: `expose`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): services \"mynginx\" already exists\n",
      "NAME                                                    TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\n",
      "db-postgresql                                           ClusterIP   10.0.6.98    <none>        5432/TCP   5h58m\n",
      "db-postgresql-hl                                        ClusterIP   None         <none>        5432/TCP   5h58m\n",
      "mynginx                                                 ClusterIP   10.0.7.161   <none>        80/TCP     19s\n",
      "python-course-021cc-kubernetes-workshop-flask-example   ClusterIP   10.0.7.56    <none>        5000/TCP   63m\n"
     ]
    }
   ],
   "source": [
    "kubectl expose deployment mynginx --port=80\n",
    "kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are certain service types that involve Kubernetes creating and attaching an external load balancer on the cloud platform - so, for instance, you can tell an AWS-based Kubernetes cluster that you want an external load balancer to point to nginx, and it will tell AWS to fire one up and show the `EXTERNAL IP` in this list, without you having to plumb it in. Your nginx processes will then be available publicly (by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short workshop to cover a lot of concepts, but lets take a brief break to check that works:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   615  100   615    0     0   215k      0 --:--:-- --:--:-- --:--:--  300k\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html>\n",
       "<head>\n",
       "<title>Welcome to nginx!</title>\n",
       "<style>\n",
       "html { color-scheme: light dark; }\n",
       "body { width: 35em; margin: 0 auto;\n",
       "font-family: Tahoma, Verdana, Arial, sans-serif; }\n",
       "</style>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Welcome to nginx!</h1>\n",
       "<p>If you see this page, the nginx web server is successfully installed and\n",
       "working. Further configuration is required.</p>\n",
       "\n",
       "<p>For online documentation and support please refer to\n",
       "<a href=\"http://nginx.org/\">nginx.org</a>.<br/>\n",
       "Commercial support is available at\n",
       "<a href=\"http://nginx.com/\">nginx.com</a>.</p>\n",
       "\n",
       "<p><em>Thank you for using nginx.</em></p>\n",
       "</body>\n",
       "</html>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IP=$(kubectl get service mynginx --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "curl http://$IP | displayHTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a step hangs, click the stop (⏹) button in the toolbar to restart bash, and re-run it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple and consistent, we will use mostly private IPs - so we can't navigate to the public URL in a browser, and instead show the output in a notebook - but the jump to public on a cloud provider is also pretty straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final bit of machinery we should see before we move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "db-postgresql-0                                                   1/1     Running   0          5h45m\n",
      "mynginx-6b78685d4d-lwnz5                                          1/1     Running   0          3m36s\n",
      "mynginx-6b78685d4d-v6xbm                                          1/1     Running   0          3m15s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-684br4ff9   1/1     Running   0          10m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pods_ are the individual processes running on a machine somewhere. Each of those is an nginx process. They are the basic unit of Kubernetes execution - here, two Pods were created as part of our Deployment (remember, we scaled it to 2 processes)\n",
    "\n",
    "Strictly, pods _can_ be more than one process. They are usually, but not always, one Docker container (which is _generally_ one OS process) - however, in some cases a \"sidecar\" container is useful. For instance, a metric-exporter process running alongside your Python app, might send regular resource usage (CPU/memory/IO) statistics to a database so you can graph performance over time. Once you see the `1/1` appearing under `READY` above, this means that all 1 of the 1 containers in the Pod are good to go.\n",
    "\n",
    "In any case, conceptually, a Pod still represents one instance of one tool/process. They are created and destroyed as part of Deployments, Jobs, and many other Kubernetes objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we tidy up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps \"mynginx\" deleted\n",
      "service \"mynginx\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete deployment mynginx\n",
    "kubectl delete service mynginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           66m\n"
     ]
    }
   ],
   "source": [
    "kubectl get deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "db-postgresql-0                                                   1/1     Running   0          5h46m\n",
      "python-course-021cc-kubernetes-workshop-flask-example-684br4ff9   1/1     Running   0          11m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All gone! (you might need to try a couple of times, while you wait for it to terminate) As the Deployment was deleted, the pods that made it up, went away too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are only a few of the Kubernetes concepts and objects, and the above is an intentionally hand-wavey introduction, to give you a feel for some key components. For the moment, we'll steer back to PHP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* docker-compose\n",
    "  * like orchestration-lite\n",
    "  * ties in closely with docker-swarm, but equally useful standalone\n",
    "  * allows your process and connections to be described in one file\n",
    "  * helps you manage variables, linking and persistance\n",
    "  * great test-bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Minikube\n",
    "  * a virtual machine for using Kubernetes on your own laptop\n",
    "  * avoids running cloud servers for development/testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Helm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Setting up Helm\n",
    "  * Helm describes itself as a Kubernetes package manager\n",
    "  * What this means is that a whole set of interlinking components, secrets, services can be described under one banner and jointly deployed as a \"Chart\"\n",
    "  * This could be a full app, or a self-backing-up database, or Thingsboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helm can tell us what charts are installed already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               \tNAMESPACE    \tREVISION\tUPDATED                                \tSTATUS  \tCHART                                  \tAPP VERSION\n",
      "db                 \tadministrator\t4       \t2023-02-25 23:34:25.664446072 +0000 UTC\tdeployed\tpostgresql-12.2.1                      \t15.2.0     \n",
      "python-course-021cc\tadministrator\t9       \t2023-02-25 23:52:09.58844083 +0000 UTC \tdeployed\tkubernetes-workshop-flask-example-0.1.0\t1.16.0     \n"
     ]
    }
   ],
   "source": [
    "helm list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected output is blank - this is because we haven't installed any charts (i.e. packages) so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting too much into all the `helm` functionality, let's start by seeing how we can deploy an nginx server to our Kubernetes cluster. Helm uses Kubernetes libraries under the hood, so your default authentication configuration (from ~/.kube/config) will get used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"moreillon\" chart repository\n",
      "...Successfully got an update from the \"python-fastapi-postgres\" chart repository\n",
      "...Successfully got an update from the \"lamp\" chart repository\n",
      "...Successfully got an update from the \"t3n\" chart repository\n",
      "...Successfully got an update from the \"hello-python-helm\" chart repository\n",
      "...Successfully got an update from the \"truecharts\" chart repository\n",
      "...Successfully got an update from the \"my-repo\" chart repository\n",
      "...Successfully got an update from the \"bitname\" chart repository\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "URL                                               \tCHART VERSION\tAPP VERSION \tDESCRIPTION                                       \n",
      "https://artifacthub.io/packages/helm/python-app...\t2.0.4        \t1.17.0      \tA Helm chart for Kubernetes                       \n",
      "https://artifacthub.io/packages/helm/python-app...\t0.1.0        \t1.16.0      \tA Helm chart for Kubernetes                       \n",
      "https://artifacthub.io/packages/helm/mikespub-h...\t0.0.1        \t            \tA generated Helm Chart for quickstart-python fr...\n",
      "https://artifacthub.io/packages/helm/hello-pyth...\t0.1.1        \t1.16.0      \tA hello world in Python                           \n",
      "https://artifacthub.io/packages/helm/devops-cha...\t0.1.0        \t1.16.0      \tA Helm chart for Kubernetes                       \n",
      "https://artifacthub.io/packages/helm/python-fas...\t0.1.0        \t1.16.0      \tA Helm chart for Kubernetes                       \n",
      "https://artifacthub.io/packages/helm/miltex/pyt...\t0.0.1        \t1.0.0       \tA Helm chart for Kubernetes                       \n",
      "https://artifacthub.io/packages/helm/ibm-charts...\t1.0.3        \t            \tIBM Data Science Experience (DSX) Developer Edi...\n",
      "https://artifacthub.io/packages/helm/inseefrlab...\t6.4.3        \tlatest      \tJupyter is a notebook accessible through a web ...\n",
      "https://artifacthub.io/packages/helm/lsst-sqre/...\t0.1.2        \t0.1.0       \tA Kafka aggregator based on the Faust Python St...\n",
      "https://artifacthub.io/packages/helm/python-web...\t1.0.0        \t1.0.0       \tA web application                                 \n",
      "https://artifacthub.io/packages/helm/reload-cou...\t0.1.0        \t1.0.1       \tA Helm chart for simple reload counter python app \n",
      "https://artifacthub.io/packages/helm/rc-helm-ch...\t0.1.1        \t3.1.0-alpha \tSaleor is a modular, high performance, headless...\n",
      "https://artifacthub.io/packages/helm/ai-chatbot...\t0.1.0        \t1.0.0       \tA python chatbot framework with Natural Languag...\n",
      "https://artifacthub.io/packages/helm/statcan/an...\t0.0.14       \t0.0.1       \tThe Portal for the Analytics Platform DAaaS Portal\n",
      "https://artifacthub.io/packages/helm/truecharts...\t11.0.10      \t4.2.1       \tAppDaemon is a loosely coupled, multi-threaded,...\n",
      "https://artifacthub.io/packages/helm/geek-cookb...\t8.4.2        \t4.0.8       \tAppDaemon is a loosely coupled, multi-threaded,...\n",
      "https://artifacthub.io/packages/helm/inseefrlab...\t4.6.0        \tlatest      \tBlazingSQL provides a high-performance distribu...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.9        \t3.4.0       \tCadQuery is an intuitive, easy-to-use Python mo...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.9        \tlatest      \tCadQuery is an intuitive, easy-to-use Python mo...\n",
      "https://artifacthub.io/packages/helm/camerahub/...\t0.10.7       \t0.36.10     \tApp for cataloguing vintage cameras, lenses, fi...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t3.0.9        \t0.2         \tChronos is a small container to run and schedul...\n",
      "https://artifacthub.io/packages/helm/statcan/ckan \t0.0.23       \t2.9.5       \tCKAN Helm Chart for Kubernetes.                   \n",
      "https://artifacthub.io/packages/helm/dsri-helm-...\t0.1.31       \t1.16.0      \tA Helm chart to deploy VisualStudio Code server...\n",
      "https://artifacthub.io/packages/helm/cloudnativ...\t2.2.1        \t1.1.0       \tDistributed computation in Python with task sch...\n",
      "https://artifacthub.io/packages/helm/dask/dask    \t2023.1.0     \t2023.1.0    \tDistributed computation in Python with task sch...\n",
      "https://artifacthub.io/packages/helm/inseefrlab...\t2.3.0        \t1           \tDask natively scales Python                       \n",
      "https://artifacthub.io/packages/helm/datacube-c...\t0.18.2       \t            \tDatacube Web Map Service                          \n",
      "https://artifacthub.io/packages/helm/datacube-c...\t0.5.29       \t            \tA Helm chart for Datacube Explorer                \n",
      "https://artifacthub.io/packages/helm/datacube-c...\t0.4.4        \t            \tDatacube OGC Web Services Indexing                \n",
      "https://artifacthub.io/packages/helm/datacube-c...\t0.19.0       \t            \tDatacube Web Map Service                          \n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.8        \tlatest      \tFlemmarr is a simple Python script that parses ...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.9        \tlatest      \tgPodder is a simple, open source podcast client...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t0.0.11       \t1.9.0       \tA fast and minimal paste bin, written in Python...\n",
      "https://artifacthub.io/packages/helm/nicholaswi...\t1.0.1        \t58edc604    \tAn automated music downloader for NZB and Torre...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t6.0.8        \t58edc604    \tAn automated music downloader for NZB and Torre...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.8        \tlatest      \tRuns a python script at a crontab defined inter...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t0.0.5        \t1.9.0       \tSelf-hosted Telegram Python Bot that dumps post...\n",
      "https://artifacthub.io/packages/helm/bitnami-ak...\t3.0.2        \t3.0.0       \tJupyterHub brings the power of notebooks to gro...\n",
      "https://artifacthub.io/packages/helm/bitnami/ju...\t3.0.10       \t3.1.1       \tJupyterHub brings the power of notebooks to gro...\n",
      "https://artifacthub.io/packages/helm/riftbit/ju...\t0.1.19       \t1.4.2       \tJupyterHub brings the power of notebooks to gro...\n",
      "https://artifacthub.io/packages/helm/dsri-helm-...\t0.1.38       \t1.16.0      \tA Helm chart to deploy JupyterLab on CPU and GP...\n",
      "https://artifacthub.io/packages/helm/deliveryhe...\t0.31.1       \t2.13.1      \tA chart to install Locust, a scalable load test...\n",
      "https://artifacthub.io/packages/helm/locust-swa...\t0.1.1        \t2.4.0       \tA chart to install Locust swarmdmin. Locust is ...\n",
      "https://artifacthub.io/packages/helm/cronce/may...\t0.1.0        \t3.4.4       \tMayan EDMS is a Free Open Source Electronic Doc...\n",
      "https://artifacthub.io/packages/helm/microfunct...\t0.1.2        \t0.1.0       \tMicroFunctions is open-source serverless platfo...\n",
      "https://artifacthub.io/packages/helm/bitnami-ak...\t3.1.6        \t1.9.1       \tApache MXNet (Incubating) is a flexible and eff...\n",
      "https://artifacthub.io/packages/helm/bitnami/mxnet\t3.1.10       \t1.9.1       \tApache MXNet (Incubating) is a flexible and eff...\n",
      "https://artifacthub.io/packages/helm/opsdroid/o...\t0.1.6        \t0.25.0      \tOpsdroid is a ChatOps bot framework written in ...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.14       \t1.18.3      \tPython script to update metadata and automatica...\n",
      "https://artifacthub.io/packages/helm/devtron/pr...\t0.2.0        \t4.2.0       \tprom2teams is a service built with Python that ...\n",
      "https://artifacthub.io/packages/helm/devtron-la...\t0.2.0        \t4.2.0       \tprom2teams is a service built with Python that ...\n",
      "https://artifacthub.io/packages/helm/cloudve/pu...\t0.1.0        \t0.9.0       \tA Python server application that allows a Galax...\n",
      "https://artifacthub.io/packages/helm/balihb-pvc...\t0.2.4        \t0.2.4       \tProvide 2 metrics to monitoring mounted PVC usa...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t8.0.8        \t5de90278    \tpyLoad is a Free and Open Source download manag...\n",
      "https://artifacthub.io/packages/helm/geek-cookb...\t6.4.2        \t0.4.20      \tpyLoad is a Free and Open Source download manag...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.18       \tlatest      \tpyLoad(https://pyload.net/) is a Free and Open ...\n",
      "https://artifacthub.io/packages/helm/cgsimmons/...\t0.1.0        \t1.3.2       \tA high availablility, persistent, auto-scaling ...\n",
      "https://artifacthub.io/packages/helm/prtg-pypro...\t1.1.4        \t1.1.4       \tRun the prtg pyprobe in your Kubernetes cluster   \n",
      "https://artifacthub.io/packages/helm/bitnami/py...\t2.5.14       \t1.13.1      \tPyTorch is a deep learning platform that accele...\n",
      "https://artifacthub.io/packages/helm/bitnami-ak...\t2.5.9        \t1.13.0      \tPyTorch is a deep learning platform that accele...\n",
      "https://artifacthub.io/packages/helm/cloudnativ...\t0.0.1        \t1.1.0       \tDeep learning platform that accelerates the tra...\n",
      "https://artifacthub.io/packages/helm/deliveryhe...\t1.0.4        \t1.0         \tA small python script that runs on a cron sched...\n",
      "https://artifacthub.io/packages/helm/rstudio/rs...\t0.3.17       \t2023.01.1   \tOfficial Helm chart for RStudio Connect           \n",
      "https://artifacthub.io/packages/helm/rstudio/rs...\t0.5.5        \t2022.11.4   \tOfficial Helm chart for RStudio Package Manager   \n",
      "https://artifacthub.io/packages/helm/rstudio/rs...\t0.5.28       \t2022.12.0   \tOfficial Helm chart for RStudio Workbench         \n",
      "https://artifacthub.io/packages/helm/vquie/seat...\t1.0.1        \t2.2.2       \tThe FAAS Scheduler is a component of SeaTable’s...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.9        \tlatest      \tURL Shortener in python based on flask            \n",
      "https://artifacthub.io/packages/helm/bitnami-ak...\t6.3.11       \t3.3.1       \tApache Spark is a high-performance engine for l...\n",
      "https://artifacthub.io/packages/helm/bitnami/spark\t6.3.17       \t3.3.2       \tApache Spark is a high-performance engine for l...\n",
      "https://artifacthub.io/packages/helm/bigdata-ch...\t6.1.10       \t3.2.1       \tApache Spark is a high-performance engine for l...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t5.0.9        \t3.5.3       \tSpeedtest Exporter made in python using the off...\n",
      "https://artifacthub.io/packages/helm/geek-cookb...\t5.4.2        \tv3.2.2      \tSpeedtest Exporter made in python using the off...\n",
      "https://artifacthub.io/packages/helm/truecharts...\t2.0.9        \tlatest      \tsqlite-web is a web-based SQLite database brows...\n",
      "https://artifacthub.io/packages/helm/rc-helm-ch...\t0.1.0        \t6           \tChart for Taiga, your opensource agile project ...\n",
      "https://artifacthub.io/packages/helm/fermosit/t...\t0.0.11       \t6.0.0-latest\tA flexible project management web application.    \n",
      "https://artifacthub.io/packages/helm/truecharts...\t13.0.17      \t2.11.1      \tA Python based monitoring and tracking tool for...\n",
      "https://artifacthub.io/packages/helm/geek-cookb...\t11.4.2       \tv2.7.7      \tA Python based monitoring and tracking tool for...\n",
      "https://artifacthub.io/packages/helm/buttahtoas...\t0.3.3        \t1.1.0       \tUnofficial Tavern Helm Chart                      \n",
      "https://artifacthub.io/packages/helm/inseefrlab...\t4.9.0        \tlatest      \tTensorFlow is a software library dedicated to m...\n",
      "https://artifacthub.io/packages/helm/thanh-vt/t...\t0.1.2        \t1.16.0      \tA Python Web App with Redis Cluter integration    \n",
      "https://artifacthub.io/packages/helm/inseefrlab...\t3.2.0        \t355         \tFast distributed SQL query engine for big data ...\n",
      "https://artifacthub.io/packages/helm/inseefrlab...\t6.9.0        \t2.6.0       \tVisual Studio Code is a lightweight yet powerfu...\n"
     ]
    }
   ],
   "source": [
    "helm repo update\n",
    "helm search hub python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We register a Helm repo (repository) to pull these charts (apps) from - for many more, see https://artifacthub.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"python-fastapi-postgres\" already exists with the same configuration, skipping\n"
     ]
    }
   ],
   "source": [
    "helm repo add python-fastapi-postgres https://archish27.github.io/python-fastapi-postgres-helm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can install from that repo - in this case, a trivially simply Python API that responds `{\"Hello\": \"World\"}` to requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helm install my-python-fastapi-postgres python-fastapi-postgres/python-fastapi-postgres --version 0.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the below that a whole series of objects have been created, including a Deployment and a Service. As we learned above, a Deployment will create one or more Pods - you can see the Pod starts with the same name and is marked \"related\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                                  READY   STATUS    RESTARTS   AGE\n",
      "pod/db-postgresql-0                                                   1/1     Running   0          5h49m\n",
      "pod/my-python-fastapi-postgres-d8c6f99b-6mcgn                         1/1     Running   0          41s\n",
      "pod/python-course-021cc-kubernetes-workshop-flask-example-684br4ff9   1/1     Running   0          14m\n",
      "\n",
      "NAME                                                            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\n",
      "service/db-postgresql                                           ClusterIP   10.0.6.98    <none>        5432/TCP   6h3m\n",
      "service/db-postgresql-hl                                        ClusterIP   None         <none>        5432/TCP   6h3m\n",
      "service/my-python-fastapi-postgres                              ClusterIP   10.0.4.143   <none>        80/TCP     41s\n",
      "service/python-course-021cc-kubernetes-workshop-flask-example   ClusterIP   10.0.7.56    <none>        5000/TCP   68m\n",
      "\n",
      "NAME                                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/my-python-fastapi-postgres                              1/1     1            1           41s\n",
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           68m\n",
      "\n",
      "NAME                                                                               DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/my-python-fastapi-postgres-d8c6f99b                                1         1         1       41s\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-57bd9cd947   0         0         0       68m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5949b56988   0         0         0       66m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5d96df79f6   0         0         0       48m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5dff498678   0         0         0       54m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-64c8d86cfd   0         0         0       23m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-65546b659b   0         0         0       45m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-677dd6f85b   0         0         0       46m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-684bf5946d   1         1         1       14m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-6c78f5ff46   0         0         0       63m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-c9dc8c4d     0         0         0       67m\n",
      "\n",
      "NAME                             READY   AGE\n",
      "statefulset.apps/db-postgresql   1/1     6h3m\n"
     ]
    }
   ],
   "source": [
    "kubectl get all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(the above may need re-run a few times until it stops showing \"Init:0/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Hello\":\"World\"}\n"
     ]
    }
   ],
   "source": [
    "IP=$(kubectl get service my-python-fastapi-postgres --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "curl http://$IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see how this type of tool is built up from Python and Dockerfiles soon, but for now, the key takeaway is that you can take a Python app, dockerize it, and run it in a process on Kubernetes (here, a deployment, consisting of one pod, consisting of one container, which runs one Python process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helm also gives us a neat way of cleaning up all the different related pieces for this app in one go -- deployments, services, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"my-python-fastapi-postgres\" uninstalled\n"
     ]
    }
   ],
   "source": [
    "helm delete my-python-fastapi-postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and sure enough (perhaps after a few seconds)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                                  READY   STATUS    RESTARTS   AGE\n",
      "pod/db-postgresql-0                                                   1/1     Running   0          5h53m\n",
      "pod/python-course-021cc-kubernetes-workshop-flask-example-684br4ff9   1/1     Running   0          18m\n",
      "\n",
      "NAME                                                            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\n",
      "service/db-postgresql                                           ClusterIP   10.0.6.98    <none>        5432/TCP   6h7m\n",
      "service/db-postgresql-hl                                        ClusterIP   None         <none>        5432/TCP   6h7m\n",
      "service/python-course-021cc-kubernetes-workshop-flask-example   ClusterIP   10.0.7.56    <none>        5000/TCP   72m\n",
      "\n",
      "NAME                                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           72m\n",
      "\n",
      "NAME                                                                               DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-57bd9cd947   0         0         0       72m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5949b56988   0         0         0       70m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5d96df79f6   0         0         0       52m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5dff498678   0         0         0       58m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-64c8d86cfd   0         0         0       27m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-65546b659b   0         0         0       49m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-677dd6f85b   0         0         0       50m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-684bf5946d   1         1         1       18m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-6c78f5ff46   0         0         0       67m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-c9dc8c4d     0         0         0       71m\n",
      "\n",
      "NAME                             READY   AGE\n",
      "statefulset.apps/db-postgresql   1/1     6h7m\n"
     ]
    }
   ],
   "source": [
    "kubectl get all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Concepts of charts and Docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extension**: So what actually _is_ a Chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a filetree of, mostly, template [YAML](https://en.wikipedia.org/wiki/YAML) files. Each of these defines a Kubernetes object, such as a Deployment, Service or Secret. This way you can have all the boilerplate in a single git-versioned Chart, dynamically dropping in per-deployment settings using a handful of templated variables at deployment time - such the public URL for nginx, or the back-up retention period for postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bitnami\" already exists with the same configuration, skipping\n",
      "NAME: wordpress\n",
      "LAST DEPLOYED: Sun Feb 26 00:44:34 2023\n",
      "NAMESPACE: administrator\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "CHART NAME: wordpress\n",
      "CHART VERSION: 15.2.46\n",
      "APP VERSION: 6.1.1\n",
      "\n",
      "** Please be patient while the chart is being deployed **\n",
      "\n",
      "Your WordPress site can be accessed through the following DNS name from within your cluster:\n",
      "\n",
      "    wordpress.administrator.svc.cluster.local (port 80)\n",
      "\n",
      "To access your WordPress site from outside the cluster follow the steps below:\n",
      "\n",
      "1. Get the WordPress URL by running these commands:\n",
      "\n",
      "  NOTE: It may take a few minutes for the LoadBalancer IP to be available.\n",
      "        Watch the status with: 'kubectl get svc --namespace administrator -w wordpress'\n",
      "\n",
      "   export SERVICE_IP=$(kubectl get svc --namespace administrator wordpress --template \"{{ range (index .status.loadBalancer.ingress 0) }}{{ . }}{{ end }}\")\n",
      "   echo \"WordPress URL: http://$SERVICE_IP/\"\n",
      "   echo \"WordPress Admin URL: http://$SERVICE_IP/admin\"\n",
      "\n",
      "2. Open a browser and access WordPress using the obtained URL.\n",
      "\n",
      "3. Login with the following credentials below to see your blog:\n",
      "\n",
      "  echo Username: user\n",
      "  echo Password: $(kubectl get secret --namespace administrator wordpress -o jsonpath=\"{.data.wordpress-password}\" | base64 -d)\n"
     ]
    }
   ],
   "source": [
    "helm repo add bitnami https://charts.bitnami.com/bitnami\n",
    "helm install wordpress bitnami/wordpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                    TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)                      AGE\n",
      "db-postgresql                                           ClusterIP      10.0.6.98     <none>          5432/TCP                     6h11m\n",
      "db-postgresql-hl                                        ClusterIP      None          <none>          5432/TCP                     6h11m\n",
      "my-release-mariadb                                      ClusterIP      10.0.11.224   <none>          3306/TCP                     81s\n",
      "my-release-wordpress                                    LoadBalancer   10.0.0.117    34.89.3.89      80:30812/TCP,443:31856/TCP   81s\n",
      "python-course-021cc-kubernetes-workshop-flask-example   ClusterIP      10.0.7.56     <none>          5000/TCP                     76m\n",
      "wordpress                                               LoadBalancer   10.0.4.46     35.246.48.199   80:30513/TCP,443:31419/TCP   65s\n",
      "wordpress-mariadb                                       ClusterIP      10.0.9.222    <none>          3306/TCP                     65s\n",
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "db-postgresql-0                                                   1/1     Running   0          5h57m\n",
      "my-release-mariadb-0                                              1/1     Running   0          81s\n",
      "my-release-wordpress-8556c94d4f-pw2qs                             0/1     Running   0          81s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-684br4ff9   1/1     Running   0          22m\n",
      "wordpress-7cb6f9675-ts7vd                                         1/1     Running   0          65s\n",
      "wordpress-mariadb-0                                               1/1     Running   0          65s\n"
     ]
    }
   ],
   "source": [
    "kubectl get services\n",
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(re-run the above until an external IP address appears and the pods say `1/1` - may take a few moments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal:  10.0.4.46\n",
      "External: http://35.246.48.199\n",
      "Administration: http://35.246.48.199/wp-admin\n",
      "Username: user\n",
      "Password: NkYyjMl4WS\n"
     ]
    }
   ],
   "source": [
    "echo \"Internal: \" $(kubectl get service wordpress --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "echo \"External: http://$(kubectl get service wordpress --output=jsonpath=\"{.status.loadBalancer.ingress[0].ip}\")\"\n",
    "echo \"Administration: http://$(kubectl get service wordpress --output=jsonpath=\"{.status.loadBalancer.ingress[0].ip}\")/wp-admin\"\n",
    "  echo Username: user\n",
    "  echo Password: $(kubectl get secret --namespace administrator wordpress -o jsonpath=\"{.data.wordpress-password}\" | base64 -d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: uninstall: Release not loaded: wordpress: release: not found\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "helm delete wordpress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we visualize this? F&T often works with PHP applications - these have a webserver (nginx), which sends data to a PHP process (phpfpm), which gets data from a database (mariadb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PHP diagram](https://s3.us-west-2.amazonaws.com/public.flaxandteal.co.uk/larakube-1-things.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try a similar idea in Python..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Example App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/jovyan/kubernetes-workshop-flask-example'...\n",
      "remote: Enumerating objects: 27, done.        \n",
      "remote: Counting objects: 100% (27/27), done.        \n",
      "remote: Compressing objects: 100% (18/18), done.        \n",
      "remote: Total 27 (delta 10), reused 25 (delta 8), pack-reused 0        \n",
      "Receiving objects: 100% (27/27), 6.98 KiB | 6.98 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n"
     ]
    }
   ],
   "source": [
    "rm -rf ~/kubernetes-workshop-flask-example; cd ~\n",
    "git clone https://github.com/flaxandteal/kubernetes-workshop-flask-example ~/kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chart.yaml  templates  values.yaml\n"
     ]
    }
   ],
   "source": [
    "cd ~/kubernetes-workshop-flask-example\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a few tools for Kubernetes, in particular an example file for setting deployment-specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Default values for kubernetes-workshop-flask-example.\n",
      "# This is a YAML-formatted file.\n",
      "# Declare variables to be passed into your templates.\n",
      "\n",
      "replicaCount: 1\n",
      "\n",
      "image:\n",
      "  repository: ghcr.io/flaxandteal/kubernetes-workshop-flask-example-app\n",
      "  pullPolicy: IfNotPresent\n",
      "  # Overrides the image tag whose default is the chart appVersion.\n",
      "  tag: \"latest\"\n",
      "\n",
      "imagePullSecrets: []\n",
      "nameOverride: \"\"\n",
      "fullnameOverride: \"\"\n",
      "\n",
      "serviceAccount:\n",
      "  # Specifies whether a service account should be created\n",
      "  create: true\n",
      "  # Annotations to add to the service account\n",
      "  annotations: {}\n",
      "  # The name of the service account to use.\n",
      "  # If not set and create is true, a name is generated using the fullname template\n",
      "  name: \"\"\n",
      "\n",
      "podAnnotations: {}\n",
      "\n",
      "podSecurityContext: {}\n",
      "  # fsGroup: 2000\n",
      "\n",
      "securityContext: {}\n",
      "  # capabilities:\n",
      "  #   drop:\n",
      "  #   - ALL\n",
      "  # readOnlyRootFilesystem: true\n",
      "  # runAsNonRoot: true\n",
      "  # runAsUser: 1000\n",
      "\n",
      "service:\n",
      "  type: ClusterIP\n",
      "  port: 5000\n",
      "\n",
      "ingress:\n",
      "  enabled: false\n",
      "  className: \"\"\n",
      "  annotations: {}\n",
      "    # kubernetes.io/ingress.class: nginx\n",
      "    # kubernetes.io/tls-acme: \"true\"\n",
      "  hosts:\n",
      "    - host: chart-example.local\n",
      "      paths:\n",
      "        - path: /\n",
      "          pathType: ImplementationSpecific\n",
      "  tls: []\n",
      "  #  - secretName: chart-example-tls\n",
      "  #    hosts:\n",
      "  #      - chart-example.local\n",
      "\n",
      "resources:\n",
      "  # We usually recommend not to specify default resources and to leave this as a conscious\n",
      "  # choice for the user. This also increases chances charts run on environments with little\n",
      "  # resources, such as Minikube. If you do want to specify resources, uncomment the following\n",
      "  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.\n",
      "  #\n",
      "  # In this case, the primary target is a ResourceQuota'd training cluster\n",
      "  limits:\n",
      "    cpu: 100m\n",
      "    memory: 128Mi\n",
      "  requests:\n",
      "    cpu: 100m\n",
      "    memory: 128Mi\n",
      "\n",
      "autoscaling:\n",
      "  enabled: false\n",
      "  minReplicas: 1\n",
      "  maxReplicas: 100\n",
      "  targetCPUUtilizationPercentage: 80\n",
      "  # targetMemoryUtilizationPercentage: 80\n",
      "\n",
      "nodeSelector: {}\n",
      "\n",
      "tolerations: []\n",
      "\n",
      "affinity: {}\n",
      "\n",
      "env:\n",
      "  DATABASE_URI: \"sqlite:////tmp/test.db\"\n"
     ]
    }
   ],
   "source": [
    "cat values.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try installing this Helm chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: python-course-021cc\n",
      "LAST DEPLOYED: Sun Feb 26 00:52:46 2023\n",
      "NAMESPACE: administrator\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "NOTES:\n",
      "1. Get the application URL by running these commands:\n",
      "  export POD_NAME=$(kubectl get pods --namespace administrator -l \"app.kubernetes.io/name=kubernetes-workshop-flask-example,app.kubernetes.io/instance=python-course-021cc\" -o jsonpath=\"{.items[0].metadata.name}\")\n",
      "  export CONTAINER_PORT=$(kubectl get pod --namespace administrator $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n"
     ]
    }
   ],
   "source": [
    "cd ~/kubernetes-workshop-flask-example\n",
    "helm install python-course-021cc ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in every type of deployment, we need to have specific custom settings for our own deployment. This answers several questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach:\n",
    "\n",
    "* **Where is our app code stored?**: In the final built images. During continuous integration (or manual building, for smaller scale), pre-prepared base images have the code added in. The built images are then tagged for that code version and pushed to a Docker image registry that the Kubernetes cluster can access.\n",
    "* **How do we keep our code secure?**: In this example, for simplicity we use the default base images, without custom app code - as such, they are pulled down from the public Docker Hub registry. However, there are private image registries within each cloud platform, e.g. AWS ECR, which Kubernetes can authenticate with to pull down images.\n",
    "* **What about secrets?**: In this particular approach, we use Kubernetes Secrets, which is simple but only a minimum bar (although, the default implementation is improving). Better practice is to use something like the Kubernetes Vault Operator, but this takes more care to set up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_None of these are hard and fast_. There are various approaches, with benefits and drawbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example-57bdlb64b   1/1     Running   0          21s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the above until it quietens down and they all say \"Running\" or \"Completed\"^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "null\n"
     ]
    }
   ],
   "source": [
    "IP=$(kubectl get service python-course-021cc-kubernetes-workshop-flask-example --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "curl http://$IP:5000/alembic_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above returns `null` this is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Work through the charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at what just started up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example-57bdlb64b   1/1     Running   0          2m20s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have only one service, it contains our code: https://github.com/flaxandteal/kubernetes-workshop-flask-example-app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We send our output to stdout by default (i.e. simply `print()` and `logging`), we find that the logs from this Pod are the logs of a `Flask`/`gunicorn` webserver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-26 00:52:53 +0000] [1] [INFO] Starting gunicorn 20.1.0\n",
      "[2023-02-26 00:52:54 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1)\n",
      "[2023-02-26 00:52:54 +0000] [1] [INFO] Using worker: sync\n",
      "[2023-02-26 00:52:54 +0000] [8] [INFO] Booting worker with pid: 8\n"
     ]
    }
   ],
   "source": [
    "FLASK_POD=$(kubectl get pods -o=name  --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example)\n",
    "kubectl logs $FLASK_POD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach also simplified life for log aggregation, where logs can be gathered from the stdout/stderr of the various Pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Github Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is CI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github provides free basic continuous integration (CI) - when done well, this is an easy, reproducible and consistent way to go from local development to built images. To follow along, you will need to have [your own Github account or sign up](https://github.com), or can look through the [details of the pipeline](https://github.com/flaxandteal/kubernetes-workshop-flask-example-app/actions/) of the existing demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to use your own account, then you [should fork](https://github.com/flaxandteal/kubernetes-workshop-flask-example-app/fork) a copy. You can clone it down here, or on your own machine/VM to make it easier to experiment. If you want to use your fork in this notebook, then set your Github username here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export GITHUB_USERNAME=philtweir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our example app is a microservice for doing Alchemy with SQL (the result of a bad pun that I couldn't let go) - we can create the Philosopher's Stone (Magnum Opus) by requiring several Substances (Mercury, Salt and Sulphur) through web requests, mixing them to get Gloop, and then cooking, washing, pickling and fermenting them in that order, to obtain the Philosopher's Stone of legend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(for anyone wondering, while vastly over-simplified, this does reflect the basic structure of the alchemical technique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as the [app itself](https://github.com/philtweir/kubernetes-workshop-flask-example-app), we have a repository for the infrastructure code (the Helm chart) used to run it: https://github.com/philtweir/kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we get down to our lowest level for today. The Python code has to be wrapped up into a `container` - this is what it sounds like, a ringfenced set of files and resources that cannot see the outside world, except as explicitly permitted. They are similar, but different to, light virtual machines (side-note: but all share one operating system kernel when running on a laptop/server) - they may be as small as tens of megabytes, or very large, but they have their own filesystem. Two key objectives are that they can be reproducibly built - through a Dockerfile, which states the recipe - and are isolated enough to run anywhere without needing to know much about their environment (we will mention the \"12 factor app\" later that codifies this philosophy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we can take a look at the `Dockerfile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kubernetes-workshop-flask-example-app'...\n",
      "remote: Enumerating objects: 157, done.        \n",
      "remote: Counting objects: 100% (157/157), done.        \n",
      "remote: Compressing objects: 100% (95/95), done.        \n",
      "remote: Total 157 (delta 58), reused 135 (delta 36), pack-reused 0        \n",
      "Receiving objects: 100% (157/157), 18.74 KiB | 6.25 MiB/s, done.\n",
      "Resolving deltas: 100% (58/58), done.\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "cd ~\n",
    "git clone https://github.com/philtweir/kubernetes-workshop-flask-example-app\n",
    "cd ~/kubernetes-workshop-flask-example-app; git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker-compose.yml  init_containers.sh\tMANIFEST.in\t  RULES.md   tests\n",
      "Dockerfile\t    init_entrypoint.sh\tREADME.md\t  setup.cfg  tox.ini\n",
      "gunicorn_config.py  magnumopus\t\trequirements.txt  setup.py\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM python:3.8-alpine\n",
      "\n",
      "RUN addgroup -S user && adduser user -S -G user\n",
      "\n",
      "WORKDIR /home/user/\n",
      "\n",
      "COPY requirements.txt   .\n",
      "COPY gunicorn_config.py .\n",
      "COPY setup.py           .\n",
      "COPY setup.cfg          .\n",
      "\n",
      "RUN apk update && apk add postgresql-dev gcc python3-dev musl-dev\n",
      "RUN pip install gunicorn\n",
      "RUN pip install -r requirements.txt\n",
      "\n",
      "USER user\n",
      "\n",
      "EXPOSE 5000\n",
      "\n",
      "ENTRYPOINT []\n",
      "\n",
      "CMD gunicorn --config ./gunicorn_config.py magnumopus.index:app\n",
      "\n",
      "COPY magnumopus         magnumopus\n"
     ]
    }
   ],
   "source": [
    "cat Dockerfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This starts from a well-known base - an official Python Docker image, with a very cut-down operating system (Alpine), and builds on top. Alpine is great for very light, small containers (which is important if you want to run 100s or 1000s in parallel on a few servers, to serve web requests in high volume) but has some optimisations that can make it difficult to use with the whole Python ecosystem -- there are also Debian and Ubuntu based images, that have the same commands and behaviour to your Linux servers/laptops but might be a little bulkier (e.g. `python:3.8-slim`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next commands build on top. As we are starting from a nearly empty operating system, we start by adding a user, and then copy our files from the repo into the container. We tell the container that it will be running as a user called `user` and will expose a port `5000` where the Python webserver (gunicorn) will expect to see web requests. Have a look at `gunicorn_config.py` for a bit more info. Finally, we copy the app itself in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build this locally with `docker build .` but the next question is, how does the container image (the output of this build) get moved onto Kubernetes to run as a new app? In short, we use Continuous Integration - handy short-lived servers that see changes comining into a git repository and re-run any commands like docker build, pushing container images to a *container (image) registry* that Kubernetes can see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pro-tip: Modern Kubernetes has Role Based Authorization Control (RBAC), so we can create deployment users with special privileges that can ensure changes go directly from Github to our Kubernetes cluster without our intervention. Historically, it was common use `kubectl` to run these commands, but now tools like AgroCD or FluxCD automate the process more robustly. It would be possible do this via `curl` calls also, to the Kubernetes API. A particular benefit of Github Actions and, for example, Gitlab-CI, is that they can run for free on the code-hoster's platform, but can also be run internally, or even _on_ Kubernetes, if you need more speed or resources when building Docker images.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are not the only options, however - Bitbucket now has a similar set-up. Jenkins, CircleCI, Concourse and others can provide these types of pipeline also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: the CI steps show some of the Docker commands that could be run locally, if you wanted to get the hang of Docker in a manual way, building images and pushing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CI on a fork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbal instructions will walk you through forking the repository and creating your own version (and CI). Once that is working, try the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example image updated\n"
     ]
    }
   ],
   "source": [
    "GITHUB_USERNAME=philtweir\n",
    "kubectl set image deployment/python-course-021cc-kubernetes-workshop-flask-example kubernetes-workshop-flask-example=ghcr.io/${GITHUB_USERNAME}/kubernetes-workshop-flask-example-app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example-c9dchs4vn   1/1     Running   0          116s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now that it is running, what have we got? First, let us see the services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                    TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example   ClusterIP   10.0.11.41   <none>        5000/TCP   29m\n"
     ]
    }
   ],
   "source": [
    "kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we showed above with Wordpress, we can use IP addresses, but within the cluster, it manages its own DNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal: http://10.0.11.41/alembic_instruction\n",
      "Equivalent alternative: http://python-course-021cc-kubernetes-workshop-flask-example.administrator:5000/alembic_instruction\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "echo \"Internal: \"http://$(kubectl get service python-course-021cc-kubernetes-workshop-flask-example --output=jsonpath=\"{.spec.clusterIP}\")/alembic_instruction\n",
    "echo \"Equivalent alternative: http://python-course-021cc-kubernetes-workshop-flask-example.${JUPYTERHUB_USER}:5000/alembic_instruction\"\n",
    "curl http://python-course-021cc-kubernetes-workshop-flask-example.${JUPYTERHUB_USER}:5000/alembic_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is `SERVICENAME.NAMESPACE` or, equivalently, `SERVICENAME.NAMESPACE.cluster.svc.local`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The namespace is a grouping mechanism, like multitenancy, where each of you can have your own resources, like services and pods, that do not interfere with each other. For convenience, I have chosen to give everybody a namespace name that is simply their username."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out the app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an app, we still need to do something with it. Remember I said it's a fancy kitchen mixer for the Philosopher's Stone? Let us do a little bash scripting to make it easier to poke at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get () {\n",
    "    curl python-course-021cc-kubernetes-workshop-flask-example.$JUPYTERHUB_USER:5000$1\n",
    "}\n",
    "post () {\n",
    "    curl    -H 'Content-Type: application/json' -X POST python-course-021cc-kubernetes-workshop-flask-example.$JUPYTERHUB_USER:5000$1 --data \"$2\"\n",
    "}\n",
    "delete () {\n",
    "    curl    -H 'Content-Type: application/json' -X DELETE python-course-021cc-kubernetes-workshop-flask-example.$JUPYTERHUB_USER:5000$1 --data \"$2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is nothing to do with Kubernetes - in fact, it is bash scripting that lets us call curl without typing the same parameters every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty the Pantry (forget any Substances that were already stored)\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "Create some Substances, so we can mix them\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "Mix the Substances to get Gloop in our Alembic (old-school mixing pot)\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "Play with the Gloop until we have the Philosopher's Stone\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "{\"message\": \"Internal Server Error\"}\n",
      "{\"message\": \"Internal Server Error\"}\n"
     ]
    }
   ],
   "source": [
    "echo Empty the Pantry \\(forget any Substances that were already stored\\)\n",
    "delete /substance\n",
    "\n",
    "echo Create some Substances, so we can mix them\n",
    "post /substance '{\"nature\": \"Mercury\"}'\n",
    "post /substance '{\"nature\": \"Salt\"}'\n",
    "post /substance '{\"nature\": \"Sulphur\"}'\n",
    "\n",
    "echo Mix the Substances to get Gloop in our Alembic \\(old-school mixing pot\\)\n",
    "post /alembic_instruction '{\"instruction_type\": \"mix\", \"natures\": \"Mercury,Salt,Sulphur\"}'\n",
    "\n",
    "echo Play with the Gloop until we have the Philosopher\\'s Stone\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"cook\"}'\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"wash\"}'\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"pickle\"}'\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"ferment\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh, that does not look good. How do we find out where all the errors came from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes debugging, as a system that has many levels, is a bigger topic than an introduction. However, to help you see where to start - try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask_restful/__init__.py\", line 467, in wrapper\n",
      "    resp = resource(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/views.py\", line 107, in view\n",
      "    return current_app.ensure_sync(self.dispatch_request)(**kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask_restful/__init__.py\", line 582, in dispatch_request\n",
      "    resp = meth(*args, **kwargs)\n",
      "  File \"/home/user/magnumopus/resources/alembic_instruction.py\", line 43, in post\n",
      "    result, consumed = instruction_handler.handle(instruction, pantry)\n",
      "  File \"/home/user/magnumopus/services/alembic_instruction_handler.py\", line 19, in handle\n",
      "    substances = [pantry.find_substances_by_nature(nature)[0] for nature in natures]\n",
      "  File \"/home/user/magnumopus/services/alembic_instruction_handler.py\", line 19, in <listcomp>\n",
      "    substances = [pantry.find_substances_by_nature(nature)[0] for nature in natures]\n",
      "  File \"/home/user/magnumopus/repositories/sqlalchemy_pantry.py\", line 20, in find_substances_by_nature\n",
      "    substances = Substance.query.filter_by(nature=nature).all()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py\", line 2773, in all\n",
      "    return self._iter().all()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py\", line 2916, in _iter\n",
      "    result = self.session.execute(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py\", line 1714, in execute\n",
      "    result = conn._execute_20(statement, params or {}, execution_options)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1705, in _execute_20\n",
      "    return meth(self, args_10style, kwargs_10style, execution_options)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py\", line 334, in _execute_on_connection\n",
      "    return connection._execute_clauseelement(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1572, in _execute_clauseelement\n",
      "    ret = self._execute_context(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1943, in _execute_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 2124, in _handle_dbapi_exception\n",
      "    util.raise_(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1900, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 736, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: substances\n",
      "[SQL: SELECT substances.id AS substances_id, substances.nature AS substances_nature, substances.state AS substances_state \n",
      "FROM substances \n",
      "WHERE substances.nature = ?]\n",
      "[parameters: ('Gloop',)]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n",
      "Exception on /alembic_instruction [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1900, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 736, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlite3.OperationalError: no such table: substances\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 1823, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 1799, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask_restful/__init__.py\", line 467, in wrapper\n",
      "    resp = resource(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/views.py\", line 107, in view\n",
      "    return current_app.ensure_sync(self.dispatch_request)(**kwargs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask_restful/__init__.py\", line 582, in dispatch_request\n",
      "    resp = meth(*args, **kwargs)\n",
      "  File \"/home/user/magnumopus/resources/alembic_instruction.py\", line 43, in post\n",
      "    result, consumed = instruction_handler.handle(instruction, pantry)\n",
      "  File \"/home/user/magnumopus/services/alembic_instruction_handler.py\", line 19, in handle\n",
      "    substances = [pantry.find_substances_by_nature(nature)[0] for nature in natures]\n",
      "  File \"/home/user/magnumopus/services/alembic_instruction_handler.py\", line 19, in <listcomp>\n",
      "    substances = [pantry.find_substances_by_nature(nature)[0] for nature in natures]\n",
      "  File \"/home/user/magnumopus/repositories/sqlalchemy_pantry.py\", line 20, in find_substances_by_nature\n",
      "    substances = Substance.query.filter_by(nature=nature).all()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py\", line 2773, in all\n",
      "    return self._iter().all()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/query.py\", line 2916, in _iter\n",
      "    result = self.session.execute(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/orm/session.py\", line 1714, in execute\n",
      "    result = conn._execute_20(statement, params or {}, execution_options)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1705, in _execute_20\n",
      "    return meth(self, args_10style, kwargs_10style, execution_options)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/sql/elements.py\", line 334, in _execute_on_connection\n",
      "    return connection._execute_clauseelement(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1572, in _execute_clauseelement\n",
      "    ret = self._execute_context(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1943, in _execute_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 2124, in _handle_dbapi_exception\n",
      "    util.raise_(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/base.py\", line 1900, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/usr/local/lib/python3.8/site-packages/sqlalchemy/engine/default.py\", line 736, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: substances\n",
      "[SQL: SELECT substances.id AS substances_id, substances.nature AS substances_nature, substances.state AS substances_state \n",
      "FROM substances \n",
      "WHERE substances.nature = ?]\n",
      "[parameters: ('Gloop',)]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    }
   ],
   "source": [
    "FLASK_POD=$(kubectl get pods -o=name  --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example)\n",
    "kubectl logs $FLASK_POD | tail -n 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of logs. However, we should recognise that we are looking at Python exceptions - that is our first clue. Our second is that it tells us a database table is missing... if we have a database (which our app does), then we should initialize it! To do this, we can use the handy `kubectl exec` to execute a pre-defined initialization routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kubectl exec -ti deploy/python-course-021cc-kubernetes-workshop-flask-example -- python -m magnumopus.initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty the Pantry (forget any Substances that were already stored)\n",
      "true\n",
      "Create some Substances, so we can mix them\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 1, \"nature\": \"Mercury\"}\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 2, \"nature\": \"Salt\"}\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 3, \"nature\": \"Sulphur\"}\n",
      "Mix the Substances to get Gloop in our Alembic (old-school mixing pot)\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 4, \"nature\": \"Gloop\"}\n",
      "Play with the Gloop until we have the Philosopher's Stone\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 4, \"nature\": \"Gloop\"}\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 4, \"nature\": \"Gloop\"}\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 4, \"nature\": \"Gloop\"}\n",
      "{\"is_philosophers_stone\": false, \"state\": [], \"id\": 4, \"nature\": \"Gloop\"}\n"
     ]
    }
   ],
   "source": [
    "echo Empty the Pantry \\(forget any Substances that were already stored\\)\n",
    "delete /substance\n",
    "\n",
    "echo Create some Substances, so we can mix them\n",
    "post /substance '{\"nature\": \"Mercury\"}'\n",
    "post /substance '{\"nature\": \"Salt\"}'\n",
    "post /substance '{\"nature\": \"Sulphur\"}'\n",
    "\n",
    "echo Mix the Substances to get Gloop in our Alembic \\(old-school mixing pot\\)\n",
    "post /alembic_instruction '{\"instruction_type\": \"mix\", \"natures\": \"Mercury,Salt,Sulphur\"}'\n",
    "\n",
    "echo Play with the Gloop until we have the Philosopher\\'s Stone\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"cook\"}'\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"wash\"}'\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"pickle\"}'\n",
    "post /alembic_instruction '{\"instruction_type\": \"process\", \"natures\": \"Gloop\", \"action\": \"ferment\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debugging doesn't just stop here though, we can also examine more configuration-type issues, outside the container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example image updated\n"
     ]
    }
   ],
   "source": [
    "kubectl set image deployment/python-course-021cc-kubernetes-workshop-flask-example kubernetes-workshop-flask-example=nonexistant/image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that, having set it to run from a non-existant Docker image, the Python server no longer exists..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS         RESTARTS   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example-6df9m4bsd   0/1     ErrImagePull   0          15s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-84556ztnq   1/1     Running        0          6m1s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes is quite clever - as you have tried to update a deployment, but the resulting pod has not been successful, Kubernetes keeps the old one running until the problem is resolved, so your running service does not break (if it can be avoided).\n",
    "\n",
    "To find out more, we can use the `kubectl describe` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:             python-course-021cc-kubernetes-workshop-flask-example-6df9m4bsd\n",
      "Namespace:        administrator\n",
      "Priority:         0\n",
      "Service Account:  python-course-021cc-kubernetes-workshop-flask-example\n",
      "Node:             gke-qarik-course-pool-1-86a27524-bds9/10.154.0.53\n",
      "Start Time:       Sun, 26 Feb 2023 01:41:41 +0000\n",
      "Labels:           app.kubernetes.io/instance=python-course-021cc\n",
      "                  app.kubernetes.io/name=kubernetes-workshop-flask-example\n",
      "                  pod-template-hash=6df99874b\n",
      "Annotations:      <none>\n",
      "Status:           Pending\n",
      "IP:               10.12.2.69\n",
      "IPs:\n",
      "  IP:           10.12.2.69\n",
      "Controlled By:  ReplicaSet/python-course-021cc-kubernetes-workshop-flask-example-6df99874b\n",
      "Containers:\n",
      "  kubernetes-workshop-flask-example:\n",
      "    Container ID:   \n",
      "    Image:          nonexistant/image\n",
      "    Image ID:       \n",
      "    Port:           5000/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Waiting\n",
      "      Reason:       ImagePullBackOff\n",
      "    Ready:          False\n",
      "    Restart Count:  0\n",
      "    Limits:\n",
      "      cpu:     100m\n",
      "      memory:  128Mi\n",
      "    Requests:\n",
      "      cpu:      100m\n",
      "      memory:   128Mi\n",
      "    Liveness:   http-get http://:http/alembic_instruction delay=0s timeout=1s period=10s #success=1 #failure=3\n",
      "    Readiness:  http-get http://:http/alembic_instruction delay=0s timeout=1s period=10s #success=1 #failure=3\n",
      "    Environment:\n",
      "      COURSE_TEST:   1\n",
      "      DATABASE_URI:  sqlite:////tmp/test.db\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-kz7bq (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             False \n",
      "  ContainersReady   False \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  kube-api-access-kz7bq:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   Guaranteed\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type     Reason     Age                From               Message\n",
      "  ----     ------     ----               ----               -------\n",
      "  Normal   Scheduled  94s                default-scheduler  Successfully assigned administrator/python-course-021cc-kubernetes-workshop-flask-example-6df9m4bsd to gke-qarik-course-pool-1-86a27524-bds9\n",
      "  Normal   BackOff    17s (x4 over 88s)  kubelet            Back-off pulling image \"nonexistant/image\"\n",
      "  Warning  Failed     17s (x4 over 88s)  kubelet            Error: ImagePullBackOff\n",
      "  Normal   Pulling    2s (x4 over 90s)   kubelet            Pulling image \"nonexistant/image\"\n",
      "  Warning  Failed     1s (x4 over 89s)   kubelet            Failed to pull image \"nonexistant/image\": rpc error: code = Unknown desc = Error response from daemon: pull access denied for nonexistant/image, repository does not exist or may require 'docker login': denied: requested access to the resource is denied\n",
      "  Warning  Failed     1s (x4 over 89s)   kubelet            Error: ErrImagePull\n",
      "\n",
      "\n",
      "Name:             python-course-021cc-kubernetes-workshop-flask-example-84556ztnq\n",
      "Namespace:        administrator\n",
      "Priority:         0\n",
      "Service Account:  python-course-021cc-kubernetes-workshop-flask-example\n",
      "Node:             gke-qarik-course-pool-1-86a27524-bds9/10.154.0.53\n",
      "Start Time:       Sun, 26 Feb 2023 01:35:55 +0000\n",
      "Labels:           app.kubernetes.io/instance=python-course-021cc\n",
      "                  app.kubernetes.io/name=kubernetes-workshop-flask-example\n",
      "                  pod-template-hash=8455854fb\n",
      "Annotations:      <none>\n",
      "Status:           Running\n",
      "IP:               10.12.2.68\n",
      "IPs:\n",
      "  IP:           10.12.2.68\n",
      "Controlled By:  ReplicaSet/python-course-021cc-kubernetes-workshop-flask-example-8455854fb\n",
      "Containers:\n",
      "  kubernetes-workshop-flask-example:\n",
      "    Container ID:   docker://1c8d1fbddd12b370db1ca4a1e61e9d6fa8f2b4e8f8bac0522f7488e4ead56290\n",
      "    Image:          ghcr.io/flaxandteal/kubernetes-workshop-flask-example-app\n",
      "    Image ID:       docker-pullable://ghcr.io/flaxandteal/kubernetes-workshop-flask-example-app@sha256:7bfdc2bb1b2ae522db9fc6c07a42daef058d9a477da622e82b08a4ee3689316c\n",
      "    Port:           5000/TCP\n",
      "    Host Port:      0/TCP\n",
      "    State:          Running\n",
      "      Started:      Sun, 26 Feb 2023 01:36:18 +0000\n",
      "    Ready:          True\n",
      "    Restart Count:  0\n",
      "    Limits:\n",
      "      cpu:     100m\n",
      "      memory:  128Mi\n",
      "    Requests:\n",
      "      cpu:      100m\n",
      "      memory:   128Mi\n",
      "    Liveness:   http-get http://:http/alembic_instruction delay=0s timeout=1s period=10s #success=1 #failure=3\n",
      "    Readiness:  http-get http://:http/alembic_instruction delay=0s timeout=1s period=10s #success=1 #failure=3\n",
      "    Environment:\n",
      "      COURSE_TEST:   1\n",
      "      DATABASE_URI:  sqlite:////tmp/test.db\n",
      "    Mounts:\n",
      "      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-nkc8b (ro)\n",
      "Conditions:\n",
      "  Type              Status\n",
      "  Initialized       True \n",
      "  Ready             True \n",
      "  ContainersReady   True \n",
      "  PodScheduled      True \n",
      "Volumes:\n",
      "  kube-api-access-nkc8b:\n",
      "    Type:                    Projected (a volume that contains injected data from multiple sources)\n",
      "    TokenExpirationSeconds:  3607\n",
      "    ConfigMapName:           kube-root-ca.crt\n",
      "    ConfigMapOptional:       <nil>\n",
      "    DownwardAPI:             true\n",
      "QoS Class:                   Guaranteed\n",
      "Node-Selectors:              <none>\n",
      "Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n",
      "                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\n",
      "Events:\n",
      "  Type     Reason     Age                    From               Message\n",
      "  ----     ------     ----                   ----               -------\n",
      "  Normal   Scheduled  7m20s                  default-scheduler  Successfully assigned administrator/python-course-021cc-kubernetes-workshop-flask-example-84556ztnq to gke-qarik-course-pool-1-86a27524-bds9\n",
      "  Normal   Pulling    7m16s                  kubelet            Pulling image \"ghcr.io/flaxandteal/kubernetes-workshop-flask-example-app\"\n",
      "  Normal   Pulled     7m3s                   kubelet            Successfully pulled image \"ghcr.io/flaxandteal/kubernetes-workshop-flask-example-app\" in 13.120015431s\n",
      "  Normal   Created    6m57s                  kubelet            Created container kubernetes-workshop-flask-example\n",
      "  Normal   Started    6m57s                  kubelet            Started container kubernetes-workshop-flask-example\n",
      "  Warning  Unhealthy  6m55s                  kubelet            Readiness probe failed: Get \"http://10.12.2.68:5000/alembic_instruction\": dial tcp 10.12.2.68:5000: connect: connection refused\n",
      "  Warning  Unhealthy  6m49s (x2 over 6m53s)  kubelet            Readiness probe failed: Get \"http://10.12.2.68:5000/alembic_instruction\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n",
      "  Warning  Unhealthy  6m49s                  kubelet            Liveness probe failed: Get \"http://10.12.2.68:5000/alembic_instruction\": context deadline exceeded (Client.Timeout exceeded while awaiting headers)\n"
     ]
    }
   ],
   "source": [
    "kubectl describe pods --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the events section (near the end), you will see a whole set of recurring errors and their frequencies. These are being sent by the `kubelet` daemon, which manages the running of actual containers on VMs (nodes) - it has noticed that it cannot pull the node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can happen quite a bit if you have, for example, private container registry credentials that are expiring too fast, are missing or are incorrect. If you want to find out more about private registry credentials, have a look at the `imagePullSecrets` setting for Pods/Deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can restore the image, like so (or with a `helm upgrade ...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example image updated\n"
     ]
    }
   ],
   "source": [
    "kubectl set image deployment/python-course-021cc-kubernetes-workshop-flask-example kubernetes-workshop-flask-example=ghcr.io/$GITHUB_USERNAME/kubernetes-workshop-flask-example-app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rollout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes provides some useful tools for managing roll-out. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example \n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "2         <none>\n",
      "3         <none>\n",
      "4         <none>\n",
      "5         <none>\n",
      "6         <none>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl rollout history deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give a bit more info by adding a certain annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example annotated\n",
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example \n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "2         <none>\n",
      "3         <none>\n",
      "4         <none>\n",
      "5         <none>\n",
      "6         fix version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl annotate deployment/python-course-021cc-kubernetes-workshop-flask-example kubernetes.io/change-cause='fix version'\n",
    "kubectl set image deployment/python-course-021cc-kubernetes-workshop-flask-example kubernetes-workshop-flask-example=ghcr.io/${GITHUB_USERNAME}/kubernetes-workshop-flask-example-app\n",
    "kubectl rollout history deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes manages lots of its decisions by forms of \"tagging\", where `annotations` and/or `labels` are used to mark a deployment/service/pod for specific behaviour or treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: apps/v1\n",
      "kind: Deployment\n",
      "metadata:\n",
      "  annotations:\n",
      "    deployment.kubernetes.io/revision: \"6\"\n",
      "    kubernetes.io/change-cause: fix version\n",
      "    meta.helm.sh/release-name: python-course-021cc\n",
      "    meta.helm.sh/release-namespace: administrator\n",
      "  creationTimestamp: \"2023-02-26T00:52:47Z\"\n",
      "  generation: 7\n",
      "  labels:\n",
      "    app.kubernetes.io/instance: python-course-021cc\n",
      "    app.kubernetes.io/managed-by: Helm\n",
      "    app.kubernetes.io/name: kubernetes-workshop-flask-example\n",
      "    app.kubernetes.io/version: 1.16.0\n",
      "    helm.sh/chart: kubernetes-workshop-flask-example-0.1.0\n",
      "  name: python-course-021cc-kubernetes-workshop-flask-example\n",
      "  namespace: administrator\n",
      "  resourceVersion: \"467853254\"\n",
      "  uid: 94cb4a98-7ffb-431b-b7fc-3e16970f1f17\n"
     ]
    }
   ],
   "source": [
    "kubectl get deployment python-course-021cc-kubernetes-workshop-flask-example -o yaml | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels, for instance, can be used as a handy filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           53m\n"
     ]
    }
   ],
   "source": [
    "kubectl get deployments --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "python-course-021cc-kubernetes-workshop-flask-example-749cknlst   1/1     Running   0          2m53s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can roll back deployments, you can require a certain minimum number of live pods at any time during the rolling update, or even decide where new Pods are scheduled on the underlying VMs/systems (termed Nodes). Kubernetes has concepts of liveness and readiness probes, so for some types of deployment, it can spot when Pods are functional or not. In addition, this allows it to undertake one of the most fundamental aspects of orchestration, replacing Pods when they become unresponsive or die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what happens if we restart the pod? (because pods are \"stateless\", this is equivalent to deleting it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"python-course-021cc-kubernetes-workshop-flask-example-7d58m4hxm\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete pods --selector=app.kubernetes.io/name=kubernetes-workshop-flask-example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "db-postgresql-0                                                   1/1     Running   0          3m58s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-7d58msmh5   0/1     Running   0          6s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"Internal Server Error\"}\n"
     ]
    }
   ],
   "source": [
    "post /substance '{\"nature\": \"Mercury\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, looks like our database disappeared. We have no concept of state right now, so nothing is saved when a pod/container restarts. We won't get into the details of `volumes` (except verbally) but suffice it to say, having an in-memory database lasts only as long as the memory. Let's try adding a real database. Helm makes this as easy as one command for most major (open source) databases!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can take a [12 factor](https://12factor.net/) approach to override aspects of the app. Firstly, we can add a postgres server..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bitnami\" already exists with the same configuration, skipping\n",
      "Release \"db\" does not exist. Installing it now.\n",
      "NAME: db\n",
      "LAST DEPLOYED: Sun Feb 26 01:47:00 2023\n",
      "NAMESPACE: administrator\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "CHART NAME: postgresql\n",
      "CHART VERSION: 12.2.1\n",
      "APP VERSION: 15.2.0\n",
      "\n",
      "** Please be patient while the chart is being deployed **\n",
      "\n",
      "PostgreSQL can be accessed via port 5432 on the following DNS names from within your cluster:\n",
      "\n",
      "    db-postgresql.administrator.svc.cluster.local - Read/Write connection\n",
      "\n",
      "To get the password for \"postgres\" run:\n",
      "\n",
      "    export POSTGRES_PASSWORD=$(kubectl get secret --namespace administrator db-postgresql -o jsonpath=\"{.data.postgres-password}\" | base64 -d)\n",
      "\n",
      "To connect to your database run the following command:\n",
      "\n",
      "    kubectl run db-postgresql-client --rm --tty -i --restart='Never' --namespace administrator --image docker.io/bitnami/postgresql:15.2.0-debian-11-r2 --env=\"PGPASSWORD=$POSTGRES_PASSWORD\" \\\n",
      "      --command -- psql --host db-postgresql -U postgres -d postgres -p 5432\n",
      "\n",
      "    > NOTE: If you access the container using bash, make sure that you execute \"/opt/bitnami/scripts/postgresql/entrypoint.sh /bin/bash\" in order to avoid the error \"psql: local user with ID 1001} does not exist\"\n",
      "\n",
      "To connect to your database from outside the cluster execute the following commands:\n",
      "\n",
      "    kubectl port-forward --namespace administrator svc/db-postgresql 5432:5432 &\n",
      "    PGPASSWORD=\"$POSTGRES_PASSWORD\" psql --host 127.0.0.1 -U postgres -d postgres -p 5432\n",
      "\n",
      "WARNING: The configured password will be ignored on new installation in case when previous Posgresql release was deleted through the helm command. In that case, old PVC will have an old password, and setting it through helm won't take effect. Deleting persistent volumes (PVs) will solve the issue.\n"
     ]
    }
   ],
   "source": [
    "helm repo add bitnami https://charts.bitnami.com/bitnami\n",
    "helm upgrade --install db bitnami/postgresql #  --set primary.resources.requests.cpu=100m --set primary.resources.requests.memory=100Mi --set primary.resources.limits.cpu=100m --set primary.resources.limits.memory=100Mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get a password (in production systems there is much more to secret management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1y1ItBfwfl\n"
     ]
    }
   ],
   "source": [
    "POSTGRES_PASSWORD=$(kubectl get secret db-postgresql -o jsonpath=\"{.data.postgres-password}\" | base64 -d)\n",
    "echo $POSTGRES_PASSWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we upgrade our chart to apply some new values - we override an environment variable (one that the Python app knows about) to give Postgres credentials, and this time, rather than passing the image as a separate setting with `set image` or `--set`, we put it all together in a single `values` file. Think of this like per-environment configuration that gets rolled into your Chart or app when it is deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "Release \"python-course-021cc\" has been upgraded. Happy Helming!\n",
      "NAME: python-course-021cc\n",
      "LAST DEPLOYED: Sun Feb 26 01:49:17 2023\n",
      "NAMESPACE: administrator\n",
      "STATUS: deployed\n",
      "REVISION: 2\n",
      "NOTES:\n",
      "1. Get the application URL by running these commands:\n",
      "  export POD_NAME=$(kubectl get pods --namespace administrator -l \"app.kubernetes.io/name=kubernetes-workshop-flask-example,app.kubernetes.io/instance=python-course-021cc\" -o jsonpath=\"{.items[0].metadata.name}\")\n",
      "  export CONTAINER_PORT=$(kubectl get pod --namespace administrator $POD_NAME -o jsonpath=\"{.spec.containers[0].ports[0].containerPort}\")\n"
     ]
    }
   ],
   "source": [
    "cd ~/kubernetes-workshop-flask-example\n",
    "git pull\n",
    "echo '\n",
    "env:\n",
    "    DATABASE_URI: \"postgresql://postgres:'${POSTGRES_PASSWORD}'@db-postgresql:5432/postgres\"\n",
    "image:\n",
    "    repository: \"ghcr.io/'${GITHUB_USERNAME}'/kubernetes-workshop-flask-example-app\"\n",
    "' > local.yaml\n",
    "helm upgrade python-course-021cc . --values local.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "db-postgresql-0                                                   1/1     Running   0          2m27s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-749cknlst   1/1     Running   0          5m31s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-7d58m4hxm   0/1     Running   0          11s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"message\": \"Internal Server Error\"}\n"
     ]
    }
   ],
   "source": [
    "post /alembic_instruction '{\"instruction_type\": \"mix\", \"natures\": \"Mercury,Salt,Sulphur\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a new DB, so we need to run our initialization again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# kubectl exec -ti deploy/python-course-021cc-kubernetes-workshop-flask-example -- python -m magnumopus.initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but let's do it a slightly neater way - rather than hacking in to an existing pod, Kubernetes lets us create a `job` which is a single-execution task, that gets its own container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch/python-course-initialize-db created\n"
     ]
    }
   ],
   "source": [
    "kubectl create job python-course-initialize-db --image=ghcr.io/${GITHUB_USERNAME}/kubernetes-workshop-flask-example-app -- /bin/sh -c \"export DATABASE_URI='postgresql://postgres:${POSTGRES_PASSWORD}@db-postgresql:5432/postgres'\n",
    "    python -m magnumopus.initialize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          COMPLETIONS   DURATION   AGE\n",
      "python-course-initialize-db   1/1           6s         7s\n",
      "NAME                                                              READY   STATUS      RESTARTS   AGE\n",
      "db-postgresql-0                                                   1/1     Running     0          3m53s\n",
      "python-course-021cc-kubernetes-workshop-flask-example-7d58msmh5   1/1     Running     0          13m\n",
      "python-course-initialize-db-8dxr9                                 0/1     Completed   0          7s\n"
     ]
    }
   ],
   "source": [
    "kubectl get jobs\n",
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a pod successfully finishes, you can see it is `Completed`. Many charts provide post-installation jobs like this automatically, to avoid the need for manual steps, but sometimes it can cause confusion if actions are taken out of sequence, or before a database is ready, so don't assume too much when writing your Chart..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch \"python-course-initialize-db\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete job python-course-initialize-db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's poke at the DB a little. Some bash scripting again will help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_sql_on_pg () {\n",
    "  kubectl exec -ti db-postgresql-0 -- /bin/sh -c \"PGPASSWORD=$POSTGRES_PASSWORD psql -U postgres -c '$1'\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           List of relations\n",
      " Schema |    Name    | Type  |  Owner   \n",
      "--------+------------+-------+----------\n",
      " public | substances | table | postgres\n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sql_on_pg \"\\dt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"nature\": \"Mercury\", \"is_philosophers_stone\": false, \"id\": 1, \"state\": []}\n"
     ]
    }
   ],
   "source": [
    "post /substance '{\"nature\": \"Mercury\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id | nature  | state \n",
      "----+---------+-------\n",
      "  1 | Mercury | \n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sql_on_pg \"SELECT * from substances\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now does state stay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pod \"db-postgresql-0\" deleted\n",
      "pod \"python-course-021cc-kubernetes-workshop-flask-example-7d58msmh5\" deleted\n",
      "pod \"python-course-initialize-db-fdgzs\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete pods --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 2, \"is_philosophers_stone\": false, \"nature\": \"Sulphur\", \"state\": []}\n"
     ]
    }
   ],
   "source": [
    "post /substance '{\"nature\": \"Sulphur\"}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(it may take a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " id | nature  | state \n",
      "----+---------+-------\n",
      "  1 | Mercury | \n",
      "  2 | Sulphur | \n",
      "(2 rows)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_sql_on_pg \"SELECT * from substances\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't spend time on volumes, but just to note that `persistent volumes` are the Kubernetes term for things like \"disks\" or cloud-based storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "data-db-postgresql-0   Bound    pvc-7fcbed01-d96c-4426-9fad-3b508f2673a6   8Gi        RWO            standard       7m41s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pvc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds to a (snapshotable) storage disk in GCP/AWS/Azure/IBM, and usually survives after the pods using it (in this case db-postgresql-0) die - the association is called being `Bound`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "\n",
    "Try deleting the postgres helm installation with `helm delete`. Create it again. Did the data survive? (use run_sql_on_pg to check)\n",
    "\n",
    "Now try deleting both the postgres helm installation and, after, delete the pvc (persistent volume claim). Now reinstall postgres with helm. Has the PV come back? Is it the same? Is the data still there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronjobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cronjobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make scheduled tasks work, we use the Kubernetes concept of Cronjobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get cronjobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see this uses a similar format to traditional cron schedules. As with the normal Laravel approach, we set this to run an artisan job every minute (`php artisan schedule:run`), and Laravel's scheduler will decide whether any of the PHP-defined tasks are due to get kicked off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite configurable - we can say how many completed Pods we want to keep, for diagnostics, and how many failed ones, how long we give them to start up, and how many attempts each will get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Running artisan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of a broader concept of Jobs. These are requests to schedule a one-off Pod to do some task or other. Kubernetes' Cronjobs are really just creating a \"Job\" each minute from a template. Jobs in general provide a reasonable way to run one-off artisan tasks also.\n",
    "\n",
    "At present, we use a barebones script to simplify this process - running it creates a fresh new Job (from the template as the Cronjob, as it happens), and sets the internal artisan arguments to whichever command line flags we pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ~/buckram/kubernetes\n",
    "./artisan.sh route:list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get a few Errors as it starts up (ending \"ContainerCreating\"), but it should follow the Pod's logs once the Pod has started. Note that this approach is non-interactive (in fact, asynchronous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see a range of Jobs that have been run, including your manual one as \"laravel-job\" and a timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in any other setting, you will want to have more than one app platform running at once: usually for development, staging and production; or perhaps blue/green deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gitlab provide tools to help manage separate environments, along with Kubernetes - some of that is quite tied to Google Kubernetes Engine, but some is platform agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a separate Helm `values.yaml` file may be sufficient to give, e.g. a dev and staging cluster. You may be happy enough to have these both on the same Kubernetes cluster, treating it as an infrastructure provider, as long as they are namespaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes does provide namespacing - the divisions are being hardened at each version, and it is possible to apply resource usage policies, user role policies and network segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                               READY   STATUS    RESTARTS   AGE\n",
      "event-exporter-gke-f66d9f855-5b2tl                 2/2     Running   0          8d\n",
      "fluentbit-gke-l2jkh                                2/2     Running   0          6d\n",
      "fluentbit-gke-v9pp5                                2/2     Running   0          10h\n",
      "gke-metrics-agent-9dbzg                            1/1     Running   0          10h\n",
      "gke-metrics-agent-dlx5d                            1/1     Running   0          8d\n",
      "konnectivity-agent-55f6dc955b-97crd                1/1     Running   0          8d\n",
      "konnectivity-agent-55f6dc955b-z4zjj                1/1     Running   0          10h\n",
      "konnectivity-agent-autoscaler-84559799b7-k66k4     1/1     Running   0          8d\n",
      "kube-dns-698cf6b7dc-5wxq9                          4/4     Running   0          10h\n",
      "kube-dns-698cf6b7dc-f54vs                          4/4     Running   0          8d\n",
      "kube-dns-autoscaler-fbc66b884-grsjh                1/1     Running   0          8d\n",
      "kube-proxy-gke-qarik-course-pool-1-86a27524-7ok5   1/1     Running   0          8d\n",
      "kube-proxy-gke-qarik-course-pool-1-86a27524-bds9   1/1     Running   0          10h\n",
      "l7-default-backend-6b99559c7d-zf7fx                1/1     Running   0          7d1h\n",
      "metrics-server-v0.5.2-866bc7fbf8-vmvls             2/2     Running   0          8d\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods -n kube-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that there are a number of Pods doing more fundamental things than nginx - providing internal DNS, managing Helm's requests, handling Kubernetes API calls, running controller loops. These are all in the `kube-system` namespace by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore everything in your own namespace - what does it all do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                                  READY   STATUS    RESTARTS   AGE\n",
      "pod/db-postgresql-0                                                   1/1     Running   0          5h10m\n",
      "pod/python-course-021cc-kubernetes-workshop-flask-example-6554gxq5q   1/1     Running   0          6m36s\n",
      "\n",
      "NAME                                                            TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE\n",
      "service/db-postgresql                                           ClusterIP   10.0.6.98    <none>        5432/TCP   5h24m\n",
      "service/db-postgresql-hl                                        ClusterIP   None         <none>        5432/TCP   5h24m\n",
      "service/python-course-021cc-kubernetes-workshop-flask-example   ClusterIP   10.0.7.56    <none>        5000/TCP   29m\n",
      "\n",
      "NAME                                                                    READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/python-course-021cc-kubernetes-workshop-flask-example   1/1     1            1           29m\n",
      "\n",
      "NAME                                                                               DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-57bd9cd947   0         0         0       29m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5949b56988   0         0         0       27m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5d96df79f6   0         0         0       9m18s\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-5dff498678   0         0         0       15m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-65546b659b   1         1         1       6m36s\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-677dd6f85b   0         0         0       7m44s\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-6c78f5ff46   0         0         0       25m\n",
      "replicaset.apps/python-course-021cc-kubernetes-workshop-flask-example-c9dc8c4d     0         0         0       28m\n",
      "\n",
      "NAME                             READY   AGE\n",
      "statefulset.apps/db-postgresql   1/1     5h24m\n"
     ]
    }
   ],
   "source": [
    "kubectl get all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubectl works on a concept of users, contexts and clusters. You might not have spotted yet, but Kubernetes does not have a concept of user accounts, per se. It does have a concept of authentication, which can be by certificates, tokens, OpenID Connect, for example, and authorization Roles, which are bound to a username matching a RoleBinding rule when it successfully authenticates. However, no separate \"User\" object exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexts allow you to specify a user, a namespace and a cluster to work with by default. Switching contexts allows you to easily manage multiple clusters and namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT   NAME              CLUSTER           AUTHINFO       NAMESPACE\n",
      "*         jupyter-cluster   jupyter-cluster   jupyter-user   administrator\n"
     ]
    }
   ],
   "source": [
    "kubectl config get-contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `~/buckram/docs` folder is a script, `update_cluster_to_ci_build_ref.sh`, to update one context from another - this can be very handy for manual promotion, where you want to have specific controls in place to control access to the update workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingresses allow you to add rules for redirecting traffic on a domain to a certain service. `kubectl` has a handy describe mode (with most objects) - for the Jupyterhub ingress, for example, it looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ kubectl get ingress --namespace jupyterhub jupyterhub-internal\n",
    "Name:             jupyterhub-internal\n",
    "Namespace:        jupyterhub\n",
    "Address:          35.239.24.66\n",
    "Default backend:  default-http-backend:80 (10.8.0.4:8080)\n",
    "TLS:\n",
    "  kubelego-tls-proxy-jupyterhub terminates scotphp.flaxandteal.co.uk\n",
    "Rules:\n",
    "  Host                       Path  Backends\n",
    "  ----                       ----  --------\n",
    "  scotphp.flaxandteal.co.uk  \n",
    "                             /   proxy-http:8000 (<none>)\n",
    "Annotations:\n",
    "Events:\n",
    "  Type    Reason  Age   From                      Message\n",
    "  ----    ------  ----  ----                      -------\n",
    "  Normal  CREATE  57m   nginx-ingress-controller  Ingress jupyterhub/jupyterhub-internal\n",
    "  Normal  UPDATE  56m   nginx-ingress-controller  Ingress jupyterhub/jupyterhub-internal\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding YAML looks something like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "apiVersion: extensions/v1beta1\n",
    "kind: Ingress\n",
    "metadata:\n",
    "  name: jupyterhub-internal\n",
    "  namespace: jupyterhub\n",
    "spec:\n",
    "  rules:\n",
    "  - host: scotphp.flaxandteal.co.uk\n",
    "    http:\n",
    "      paths:\n",
    "      - backend:\n",
    "          serviceName: proxy-http\n",
    "          servicePort: 8000\n",
    "        path: /\n",
    "  tls:\n",
    "  - hosts:\n",
    "    - scotphp.flaxandteal.co.uk\n",
    "    secretName: TLSSECRET\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, you will notice that there is a Kubernetes Secret required. This represents the SSL certificate. One option to manage these, which is an evolution of `kube-lego` amongst other tools is `cert-manager` - it can be installed as a Helm chart and will watch for Ingresses to work out which certificates to request (and from where). For more information, see [http://docs.cert-manager.io/en/latest/](http://docs.cert-manager.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(note for minikube users: if using this with minikube, you will need to run `minikube addons enable ingress` on the host. When an ingress is created, you should also add a rule to `/etc/hosts` to direct traffic for that domain to the output of `minikube ip`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health, Logging and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of monitoring solutions available. CoreOS, one of the driver organizations behind containerization, have provided a [Kubernetes Operator for Prometheus](https://github.com/coreos/prometheus-operator) - Operators are a relative recent, powerful tool for making Kubernetes more extensible, and allowing automated control loops, for example, to take care of dynamically-defined types of object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing this operator, which can be done with `helm`, adds in several new types of Kubernetes object: PrometheusRule and AlertingRule being two examples. The operator can then keep a cluster-hosted Prometheus server dynamically changing its configuration as those are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional Helm chart, [kube-prometheus](https://github.com/coreos/prometheus-operator/tree/master/helm/kube-prometheus) builds on this to provide live feeds of Pod, Service, Node resource usage, and alerting based off that. We have implemented a basic monitoring chart that adds support for Laravel failed job and exception tracking and alerts. While some of this can be done through the framework, this ensures that metrics and alerting can be managed centrally, and that individual, scaled out web-serving or queue processes are not responsible for contacting external APIs - rather they feed it back internally to be grouped, rate-managed, etc. in a standard way with the rest of the infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log aggregation (fluentbit, fluentd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the deployment, we create fluent-bit DaemonSets - these are essentially Deployments that run one Pod on each Node (VM). Gathering logs is a perfect application for them. Fluent-bit is a reimplementation in C of a lot of Fluentd's functionality. Fluent-bit can gather logs from the containers' stdout/stderr and send these to Fluentd, or to a number of other aggregators, such as Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helm list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kubectl logs $(kubectl get pods --selector=app=buckram-fluentd -o=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Autoscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to scale the number of deployed Pods automatically, using a HorizontalPodAutoscaler object, which responds to [predefined or custom metrics](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/). This is simplest to set up for CPU requests, but can work off, for example, [Prometheus metrics](https://github.com/directxman12/k8s-prometheus-adapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, [Cluster Autoscaling](https://github.com/kubernetes/autoscaler) (where the number of Nodes changes) is cloud provider dependent. This is well-established especially for GKE, but also available for other Kubernetes providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minikube\n",
    "\n",
    "(time permitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "minikube start\n",
    "[wait]\n",
    "kubectl get nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show you one node - the VM that is running Kubernetes, and all that is on it. In normal usage, you would have a larger set of nodes - many setups will have a pool of nodes for masters, usually high in CPU resources, and a pool of nodes, perhaps smaller and more plentiful for granular horizontal scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the VM itself, once it has settled down, by running `minikube ssh`. Even more, you can see where Kubernetes rubber hits the road - if you run `docker ps`, you will see all the containers that make up Kubernetes and its apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an nginx deployment on minikube - check the output of `minikube ip` to see where it will be visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are finished, you can stop minikube with `minikube stop`, or delete it with `minikube delete`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docker-Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have `docker-compose` installed, clone down the https://gitlab.com/flaxandteal/buckram-demo-with-sample-docker Gitlab repository locally (your fork if you have it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "docker run -v $(pwd):/app composer install # or any other means of running composer, if you have it locally\n",
    "cp .env.example .env\n",
    "chmod -R ugo+rwX storage/logs bootstrap/cache   \n",
    "./dartisan key:generate\n",
    "./dartisan migrate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now be able to see a blank Laravel app at `localhost:8000` in your browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Run `make:auth` to scaffold login functionality. Can you get this running in Gitlab-CI and update it on the cluster here? In general, don't forget any migration and seeding that needs done on the live tool with `./artisan.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise (includes some Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start from a blank Laravel app. Run:\n",
    "```\n",
    "git init\n",
    "git submodule add https://gitlab.com/flaxandteal/buckram-starter infrastructure\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Python script (if you are comfortable to do so) from ./infrastructure/python - this can be done with `pip3 install --user .` for instance and run `bookcloth local:initialize` in that directory. This should create a default docker-compose setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push this to a new public Gitlab repo, and check it runs the CI. Update the images as above to run it in this cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you enjoyed this workshop and am looking forward to feedback!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Follow-up course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Shell Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Development:\n",
    "```\n",
    "export PATH=~/.local/bin:$PATH\n",
    "git clone https://gitlab.com/flaxandteal/buckram-demo-with-sample-docker\n",
    "cd buckram-demo                                                                                                                                  \n",
    "docker run -v $(pwd):/app composer install\n",
    "git submodule init\n",
    "git submodule update\n",
    "(cd infrastructure; git pull origin master; git checkout master)\n",
    "cp .env.example .env\n",
    "./dartisan key:generate\n",
    "./dartisan migrate\n",
    "lynx localhost:8000\n",
    "```\n",
    "\n",
    "Helm Setup:\n",
    "```\n",
    "wget https://storage.googleapis.com/kubernetes-helm/helm-v2.11.0-linux-amd64.tar.gz \n",
    "tar -xzf helm-v2.11.0-linux-amd64.tar.gz\n",
    "mv linux-amd64/helm ~/.local/bin\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
