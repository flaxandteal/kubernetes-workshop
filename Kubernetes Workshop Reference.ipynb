{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* setting up a generic Kubernetes system\n",
    "* deploying Laravel onto it using Helm charts (versionable infrastructure description), with Postgres, Redis and workers\n",
    "* employing a Gitlab repository for CI/CD for building container images\n",
    "* managing per-deployment configuration and environment variables\n",
    "* process health, logging and scaling\n",
    "* using the artisan CLI tool for scheduled and one-off jobs on the cluster (as time permits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "./setup_account.sh\n",
    "export USER=$GIT_COMMITTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kubernetes Workshop\n",
    "\n",
    "With Phil Weir\n",
    "(the Belfast guy who is somewhere near this projector, hopefully)\n",
    "\n",
    "* Structure of course\n",
    "* Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial set-up: _15min_ (-> 0:15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Kubernetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_10 min_ (-> 0:25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How is this relevant to PHP?\n",
    "  * Scalable\n",
    "  * Systematic\n",
    "  * Within control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why Kubernetes over alternatives?\n",
    "  * Other container orchestrators\n",
    "    * Popularity and backing\n",
    "    * Good balance of simplicity and complexity\n",
    "  * IaaS/PaaS\n",
    "    * Doesn't tie you to a single provider\n",
    "    * Can be run off-cloud\n",
    "    * Can be run on a dev machine\n",
    "    * Abstracts and automates the provider-specific bits (mostly)\n",
    "    * Separates out hardware from application infrastructure (containers vs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Brief (re)introduction to Docker\n",
    "  * If you aren't already familiar with it, you can think of a docker _container_ as a VM that shares a kernel with the host\n",
    "    * ...but don't as that loses key important differences\n",
    "  * Recommended practice is to have one process per container\n",
    "    * containers are very memory light compared to VMs, so this is much less wasteful than it may sound\n",
    "    * this provides encapsulation and makes scaling easier\n",
    "  * `docker-compose` is an _extremely_ handy tool that takes a short, app-specific _docker-compose.yml_ file as input and spins up a multi-container environment with all the expected dependencies and links\n",
    "    * you can keep the `docker-compose.yml` file in the repo with your app\n",
    "    * between docker and docker-compose, you can provide a rough alternative to VirtualBox and Vagrant developer flow (although those do not map directly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_5 min_ (-> 0:30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cloud\n",
    "  * GKE: gcloud\n",
    "  * AWS: EKS\n",
    "  * Azure: AKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Manually (kubeadm / Kubernetes the Hard Way --->)\n",
    "  * kops\n",
    "  * kubeadm\n",
    "  * Kubernetes the Hard Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Minikube...\n",
    "  * Those who want to follow along, please do\n",
    "  * Those who are happy to use the online system, please do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_15 min_ (-> 0:45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GETTING STARTED - kubectl, minikube, git, docker-compose and docker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git version 2.17.1\n"
     ]
    }
   ],
   "source": [
    "git version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Version: version.Info{Major:\"1\", Minor:\"11\", GitVersion:\"v1.11.2\", GitCommit:\"bb9ffb1654d4a729bb4cec18ff088eacc153c239\", GitTreeState:\"clean\", BuildDate:\"2018-08-07T23:17:28Z\", GoVersion:\"go1.10.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n",
      "Server Version: version.Info{Major:\"1\", Minor:\"10+\", GitVersion:\"v1.10.6-gke.4\", GitCommit:\"39a7d039cc0b45c80f755125d0506e44555ed405\", GitTreeState:\"clean\", BuildDate:\"2018-09-13T22:15:39Z\", GoVersion:\"go1.9.3b4\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
     ]
    }
   ],
   "source": [
    "kubectl version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, I will talk a little bit about basic Kubernetes tools and concepts, then we can start building up practical steps..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language of Kubernetes communication is JSON, under the hood, but generally the tooling lets you talk to it in YAML, which is actually a (much more readable) superset. Instead of\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"apiVersion\": \"v1\",\n",
    "    \"type\": \"Pod\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"hi-pod\"\n",
    "    }\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "we can write\n",
    "\n",
    "```yaml\n",
    "apiVersion: v1\n",
    "type: Pod\n",
    "metadata:\n",
    "    name: \"hi-pod\"\n",
    "```\n",
    "\n",
    "We can build up all our Kubernetes objects on the cluster by sending declarative YAML files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Just nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to interact with a Kubernetes cluster is the `kubectl` tool. It's preinstalled here, but you can download it yourself locally. The configuration files are called `kubeconfig` files, and the default one lives at `~/.kube/config` on Mac/*nix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/mynginx created\n"
     ]
    }
   ],
   "source": [
    "kubectl run mynginx --image=nginx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `run` command is not so common day-to-day, but is an opinionated shortcut, bundling a couple of more common steps, to get a Docker image running on a cluster as a standalone application or \"deployment\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A _deployment_ is essentially a single application (perhaps running many times). It is normally one or more replicas of a specific process (in this case nginx), maybe with some helper process or some start-up/shutdown actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\n",
      "mynginx   1         1         1            0           3s\n"
     ]
    }
   ],
   "source": [
    "kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run two identical instances of nginx, by scaling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions/mynginx scaled\n",
      "NAME      DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\n",
      "mynginx   2         2         2            1           2m\n"
     ]
    }
   ],
   "source": [
    "kubectl scale deployment mynginx --replicas=2\n",
    "kubectl get deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for us to interact with nginx we have to encounter another concept: _services_ . Traditionally in the PHP ecosystem, we often think of a process and the service it provides as essentially equivalent - however, modern orchestration tools help decouple the idea of an advertised service (_services_) and the processes backing them up (_deployments_).\n",
    "\n",
    "This means that we can link up different tools with them only knowing each others' services - Kubernetes will route requests through to the deployed processes behind the scenes, with simple load balancing. For example, there could be 100 nginx processes spread over a dozen VMs and any internal or external request just asks for the nginx service and magically gets a reply.\n",
    "\n",
    "We still need to create a service though... as with `run` for deployments, there is a command to bundle a couple of steps: `expose`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/mynginx exposed\n",
      "NAME      TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\n",
      "mynginx   ClusterIP   10.15.254.252   <none>        80/TCP    1s\n"
     ]
    }
   ],
   "source": [
    "kubectl expose deployment mynginx --port=80\n",
    "kubectl get services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are certain service types that involve Kubernetes creating and attaching an external load balancer on the cloud platform - so, for instance, you can tell an AWS-based Kubernetes cluster that you want an external load balancer to point to nginx, and it will tell AWS to fire one up and show the `EXTERNAL IP` in this list, without you having to plumb it in. Your nginx processes will then be available publicly (by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a short workshop to cover a lot of concepts, but lets take a brief break to check that works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "<head>\n",
      "<title>Welcome to nginx!</title>\n",
      "<style>\n",
      "    body {\n",
      "        width: 35em;\n",
      "        margin: 0 auto;\n",
      "        font-family: Tahoma, Verdana, Arial, sans-serif;\n",
      "    }\n",
      "</style>\n",
      "</head>\n",
      "<body>\n",
      "<h1>Welcome to nginx!</h1>\n",
      "<p>If you see this page, the nginx web server is successfully installed and\n",
      "working. Further configuration is required.</p>\n",
      "\n",
      "<p>For online documentation and support please refer to\n",
      "<a href=\"http://nginx.org/\">nginx.org</a>.<br/>\n",
      "Commercial support is available at\n",
      "<a href=\"http://nginx.com/\">nginx.com</a>.</p>\n",
      "\n",
      "<p><em>Thank you for using nginx.</em></p>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "IP=$(kubectl get service mynginx --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "curl http://$IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[In another notebook](/user/philtweir/notebooks/kubernetes-scotlandphp/visual-notebook.ipynb), there is a bit of Python for showing a snippet view of the rendered page. We will use this further later also, so do open it in a new tab and check it works.\n",
    "\n",
    "To keep things simple and consistent, we will use private IPs - so we can't navigate to the public URL in a browser, and instead show the output in a notebook - but the jump to public on a cloud provider is also pretty straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One final bit of machinery we should see before we move on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       READY     STATUS    RESTARTS   AGE\n",
      "mynginx-7f77c9fb4c-9lmbh   1/1       Running   0          1m\n",
      "mynginx-7f77c9fb4c-r9sfz   1/1       Running   0          3m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pods_ are the individual processes running on a machine somewhere. Each of those is an nginx process. They are the basic unit of Kubernetes execution - here, two Pods were created as part of our Deployment (remember, we scaled it to 2 processes)\n",
    "\n",
    "Strictly, pods _can_ be more than one process. They are usually, but not always one Docker container (which is _generally_ one OS process) - however, in some cases a \"sidecar\" container is useful. For instance, a postgres metric-exporter process running alongside the postgres database process, that sends resource usage stats. You see the `1/1` appearing under `READY` above - this means that all 1 of the 1 containers in the Pod are good to go.\n",
    "\n",
    "In any case, conceptually, a Pod still represents one instance of one tool. They are created and destroyed as part of Deployments, Jobs, and many other Kubernetes objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we tidy up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions \"mynginx\" deleted\n",
      "service \"mynginx\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete deployment mynginx\n",
    "kubectl delete service mynginx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found.\n"
     ]
    }
   ],
   "source": [
    "kubectl get deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       READY     STATUS        RESTARTS   AGE\n",
      "mynginx-7f77c9fb4c-r9sfz   0/1       Terminating   0          3m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All gone! (you might need to try a couple of times, while you wait for it to terminate) As the Deployment was deleted, the pods that made it up, went away too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are only a few of the Kubernetes concepts and objects, and the above is an intentionally hand-wavey introduction, to give you a feel for some key components. For the moment, we'll steer back to PHP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_20 min_ (-> 1:05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* docker-compose\n",
    "  * like orchestration-lite\n",
    "  * ties in closely with docker-swarm, but equally useful standalone\n",
    "  * allows your process and connections to be described in one file\n",
    "  * helps you manage variables, linking and persistance\n",
    "  * great test-bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Buckram\n",
    "  * an evolving set of git-based configuration templates\n",
    "  * one of many options, helping to go from source repo to dockerized, deployable app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Go through key points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Bare LAMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_25 min_ (-> 1:30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Setting up Helm\n",
    "  * Helm describes itself as a Kubernetes package manager\n",
    "  * What this means is that a whole set of interlinking components, secrets, services can be described under one banner and jointly deployed as a \"Chart\"\n",
    "  * This could be a full app, or a self-backing-up database, or monitoring service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When setting Helm up on a new cluster, you should run `helm init`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$HELM_HOME has been configured at /home/jovyan/.helm.\n",
      "Warning: Tiller is already installed in the cluster.\n",
      "(Use --client-only to suppress this message, or --upgrade to upgrade Tiller to the current version.)\n",
      "Happy Helming!\n"
     ]
    }
   ],
   "source": [
    "export TILLER_NAMESPACE=$GIT_COMMITTER_NAME\n",
    "helm init --service-account jupyter-user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sets up a daemon on the cluster, called `tiller` (you can sea the theme...), which manages the actual deployment. The local `helm` binary mostly communicates with this daemon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helm can tell us what charts are installed already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "helm list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without getting too much into all the `helm` functionality, let's start by seeing how we can deploy an nginx server to our Kubernetes cluster. Helm uses Kubernetes libraries under the hood, so your default authentication configuration (from ~/.kube/config) will get used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Skip local chart repository\n",
      "...Successfully got an update from the \"stable\" chart repository\n",
      "Update Complete. ⎈ Happy Helming!⎈ \n",
      "NAME             \tCHART VERSION\tAPP VERSION            \tDESCRIPTION                                       \n",
      "stable/phpbb     \t3.0.2        \t3.2.3                  \tCommunity forum that supports the notion of use...\n",
      "stable/phpmyadmin\t1.1.1        \t4.8.2                  \tphpMyAdmin is an mysql administration frontend    \n",
      "stable/joomla    \t3.0.2        \t3.8.12                 \tPHP content management system (CMS) for publish...\n",
      "stable/lamp      \t0.1.5        \t5.7                    \tModular and transparent LAMP stack chart suppor...\n",
      "stable/mediawiki \t4.0.3        \t1.31.1                 \tExtremely powerful, scalable software and a fea...\n",
      "stable/osclass   \t3.0.2        \t3.7.4                  \tOsclass is a php script that allows you to quic...\n",
      "stable/dokuwiki  \t3.0.2        \t0.20180422.201805030840\tDokuWiki is a standards-compliant, simple to us...\n",
      "stable/drupal    \t2.0.2        \t8.6.1                  \tOne of the most versatile open source content m...\n",
      "stable/magento   \t3.0.2        \t2.2.6                  \tA feature-rich flexible e-commerce solution. It...\n",
      "stable/moodle    \t3.0.2        \t3.5.2                  \tMoodle is a learning platform designed to provi...\n",
      "stable/opencart  \t3.0.2        \t3.0.2-0                \tA free and open source e-commerce platform for ...\n",
      "stable/orangehrm \t3.0.2        \t4.1.2                  \tOrangeHRM is a free HR management system that o...\n",
      "stable/owncloud  \t3.0.1        \t10.0.10                \tA file sharing server that puts the control and...\n",
      "stable/prestashop\t3.1.2        \t1.7.4-2                \tA popular open source ecommerce solution. Profe...\n",
      "stable/testlink  \t3.0.2        \t1.9.17                 \tWeb-based test management system that facilitat...\n",
      "stable/wordpress \t3.0.2        \t4.9.8                  \tWeb publishing platform for building blogs and ...\n"
     ]
    }
   ],
   "source": [
    "helm repo update\n",
    "helm search php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   mylamp\n",
      "LAST DEPLOYED: Wed Oct  3 22:30:57 2018\n",
      "NAMESPACE: scotlandphp-XXXXX\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/Secret\n",
      "NAME         TYPE    DATA  AGE\n",
      "mylamp-lamp  Opaque  0     0s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME               DATA  AGE\n",
      "mylamp-lamp-httpd  3     0s\n",
      "mylamp-lamp-php    2     0s\n",
      "\n",
      "==> v1/PersistentVolumeClaim\n",
      "NAME         STATUS   VOLUME    CAPACITY  ACCESS MODES  STORAGECLASS  AGE\n",
      "mylamp-lamp  Pending  standard  0s\n",
      "\n",
      "==> v1/Service\n",
      "NAME         TYPE          CLUSTER-IP    EXTERNAL-IP  PORT(S)       AGE\n",
      "mylamp-lamp  LoadBalancer  10.15.252.28  <pending>    80:32431/TCP  0s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME         DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "mylamp-lamp  1        1        1           0          0s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                         READY  STATUS   RESTARTS  AGE\n",
      "mylamp-lamp-ff75d949d-v5nk7  0/2    Pending  0         0s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "INIT:\n",
      "      Please wait for all init containers to finish before connecting to\n",
      "      the charts services. This might take a few minutes depending on their\n",
      "      tasks.\n",
      "\n",
      "LOADBALANCER:\n",
      "      Please wait until the service has been routed to an IP address.\n",
      "      You can watch the status of by running 'kubectl get svc -w mylamp-lamp'\n",
      "\n",
      "1. You can now connect to the following services:\n",
      "      export CHARTIP=$(kubectl get svc mylamp-lamp --output=jsonpath={.status.loadBalancer.ingress..ip})\n",
      "\n",
      "      Main Site:\n",
      "        http://$CHARTIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "helm install stable/lamp --name mylamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see from the lines starting with `==>` that a whole series of objects have been created, including a Deployment and a Service. As we learned above, a Deployment will create one or more Pods - you can see the Pod starts with the same name and is marked \"related\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME            TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)        AGE\n",
      "mylamp-lamp     LoadBalancer   10.15.252.28    35.197.238.10   80:32431/TCP   1m\n",
      "tiller-deploy   ClusterIP      10.15.252.217   <none>          44134/TCP      5m\n",
      "NAME                            READY     STATUS    RESTARTS   AGE\n",
      "mylamp-lamp-ff75d949d-v5nk7     2/2       Running   0          1m\n",
      "tiller-deploy-d8db78b5b-68spl   1/1       Running   0          3m\n"
     ]
    }
   ],
   "source": [
    "kubectl get services\n",
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>403 Forbidden</title>\n",
      "</head><body>\n",
      "<h1>Forbidden</h1>\n",
      "<p>You don't have permission to access /\n",
      "on this server.<br />\n",
      "</p>\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "IP=$(kubectl get service mylamp-lamp --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "curl http://$IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, this does makes sense - our LAMP server has no particular PHP app set up on it, so there's nothing to serve - rather than giving a meaningless default page when the app is missing, it gives access denied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the contributors of the `stable/lamp` Chart expect us to provide custom configuration when deploying, for instance, for a Wordpress or custom app deployment. There's no reason we _have_ to use this chart to do that (there's also a separate Wordpress chart above, for instance). We will show a more complete app, while we explore more of helm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"mylamp\" deleted\n"
     ]
    }
   ],
   "source": [
    "helm delete --purge mylamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Concepts of charts and Docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what actually _is_ a Chart?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a filetree of, mostly, template [YAML](https://en.wikipedia.org/wiki/YAML) files. Each of these defines a Kubernetes object, such as a Deployment, Service or Secret. This way you can have all the boilerplate in a single git-versioned Chart, dynamically dropping in per-deployment settings using a handful of templated variables at deployment time - such the public URL for nginx, or the back-up retention period for postgres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/jovyan/helm-charts'...\n",
      "remote: Enumerating objects: 2, done.        \n",
      "remote: Counting objects: 100% (2/2), done.        \n",
      "remote: Compressing objects: 100% (2/2), done.        \n",
      "remote: Total 40880 (delta 0), reused 1 (delta 0), pack-reused 40878        \n",
      "Receiving objects: 100% (40880/40880), 12.14 MiB | 18.89 MiB/s, done.\n",
      "Resolving deltas: 100% (27167/27167), done.\n"
     ]
    }
   ],
   "source": [
    "rm -rf ~/helm-charts\n",
    "git clone https://github.com/helm/charts ~/helm-charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acs-engine-autoscaler\thubot\t\t\t pachyderm\n",
      "aerospike\t\tinbucket\t\t parse\n",
      "anchore-engine\t\tinfluxdb\t\t percona\n",
      "apm-server\t\tipfs\t\t\t percona-xtradb-cluster\n",
      "ark\t\t\tjanusgraph\t\t phabricator\n",
      "artifactory\t\tjasperreports\t\t phpbb\n",
      "artifactory-ha\t\tjenkins\t\t\t phpmyadmin\n",
      "auditbeat\t\tjoomla\t\t\t postgresql\n",
      "aws-cluster-autoscaler\tk8s-spot-rescheduler\t prestashop\n",
      "bitcoind\t\tkanister-operator\t presto\n",
      "bookstack\t\tkapacitor\t\t prometheus\n",
      "buildkite\t\tkatafygio\t\t prometheus-adapter\n",
      "burrow\t\t\tkeel\t\t\t prometheus-blackbox-exporter\n",
      "centrifugo\t\tkeycloak\t\t prometheus-cloudwatch-exporter\n",
      "cerebro\t\t\tkiam\t\t\t prometheus-mysql-exporter\n",
      "cert-manager\t\tkibana\t\t\t prometheus-node-exporter\n",
      "chaoskube\t\tkong\t\t\t prometheus-postgres-exporter\n",
      "chartmuseum\t\tkube2iam\t\t prometheus-pushgateway\n",
      "chronograf\t\tkubed\t\t\t prometheus-rabbitmq-exporter\n",
      "cluster-autoscaler\tkubedb\t\t\t prometheus-redis-exporter\n",
      "cockroachdb\t\tkube-lego\t\t prometheus-to-sd\n",
      "concourse\t\tkube-ops-view\t\t quassel\n",
      "consul\t\t\tkubernetes-dashboard\t rabbitmq\n",
      "coredns\t\t\tkuberos\t\t\t rabbitmq-ha\n",
      "coscale\t\t\tkube-slack\t\t redis\n",
      "dask\t\t\tkube-state-metrics\t redis-ha\n",
      "dask-distributed\tkubewatch\t\t redmine\n",
      "datadog\t\t\tkured\t\t\t rethinkdb\n",
      "dex\t\t\tlamp\t\t\t risk-advisor\n",
      "distributed-tensorflow\tlinkerd\t\t\t rocketchat\n",
      "distribution\t\tlocust\t\t\t rookout\n",
      "dmarc2logstash\t\tluigi\t\t\t sapho\n",
      "docker-registry\t\tmagento\t\t\t schema-registry-ui\n",
      "dokuwiki\t\tmagic-namespace\t\t searchlight\n",
      "drone\t\t\tmailhog\t\t\t selenium\n",
      "drupal\t\t\tmariadb\t\t\t sematext-docker-agent\n",
      "efs-provisioner\t\tmattermost-team-edition  sensu\n",
      "elastabot\t\tmcrouter\t\t sentry\n",
      "elastalert\t\tmediawiki\t\t seq\n",
      "elasticsearch-exporter\tmemcached\t\t signalfx-agent\n",
      "envoy\t\t\tmetabase\t\t sonarqube\n",
      "etcd-operator\t\tmetallb\t\t\t sonatype-nexus\n",
      "ethereum\t\tmetricbeat\t\t spark\n",
      "eventrouter\t\tmetrics-server\t\t spartakus\n",
      "express-gateway\t\tminecraft\t\t spinnaker\n",
      "external-dns\t\tminio\t\t\t spotify-docker-gc\n",
      "factorio\t\tmission-control\t\t stackdriver-exporter\n",
      "falco\t\t\tmongodb\t\t\t stash\n",
      "filebeat\t\tmongodb-replicaset\t stolon\n",
      "fluent-bit\t\tmoodle\t\t\t suitecrm\n",
      "fluentd-elasticsearch\tmsoms\t\t\t sumokube\n",
      "g2\t\t\tmssql-linux\t\t sumologic-fluentd\n",
      "gce-ingress\t\tmysql\t\t\t superset\n",
      "gcloud-endpoints\tmysqldump\t\t swift\n",
      "gcloud-sqlproxy\t\tnamerd\t\t\t sysdig\n",
      "gcp-night-king\t\tnats\t\t\t telegraf\n",
      "ghost\t\t\tneo4j\t\t\t tensorflow-notebook\n",
      "gitlab-ce\t\tnewrelic-infrastructure  tensorflow-serving\n",
      "gitlab-ee\t\tnfs-client-provisioner\t testlink\n",
      "gocd\t\t\tnfs-server-provisioner\t tomcat\n",
      "grafana\t\t\tnginx-ingress\t\t traefik\n",
      "graphite\t\tnginx-ldapauth-proxy\t uchiwa\n",
      "hackmd\t\t\tnginx-lego\t\t unbound\n",
      "hadoop\t\t\toauth2-proxy\t\t vault-operator\n",
      "hazelcast\t\todoo\t\t\t verdaccio\n",
      "heapster\t\topencart\t\t voyager\n",
      "heartbeat\t\topenebs\t\t\t weave-cloud\n",
      "hlf-ca\t\t\topeniban\t\t weave-scope\n",
      "hlf-couchdb\t\topenldap\t\t wordpress\n",
      "hlf-ord\t\t\topenvpn\t\t\t xray\n",
      "hlf-peer\t\torangehrm\t\t zeppelin\n",
      "home-assistant\t\tosclass\t\t\t zetcd\n",
      "horovod\t\t\towncloud\n"
     ]
    }
   ],
   "source": [
    "cd ~/helm-charts/stable\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various chart repositories available (check out bitnami's as well the helm ones), but this is the git repo used to build the default stable repository. You can see the variety of charts currently there. Lets look inside the `lamp` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "./README.md\n",
      "./files\n",
      "./files/httpd\n",
      "./files/httpd/httpd-vhosts.conf\n",
      "./files/httpd/httpd-vhosts-socket.conf\n",
      "./files/httpd/httpd.conf\n",
      "./files/init\n",
      "./files/init/init_wp.sh\n",
      "./files/init/init_wp_db.sh\n",
      "./files/init/init_clone.sh\n",
      "./files/init/init_db_clone.sh\n",
      "./values.yaml\n",
      "./templates\n",
      "./templates/ingress.yaml\n",
      "./templates/NOTES.txt\n",
      "./templates/_helpers.tpl\n",
      "./templates/pvc.yaml\n",
      "./templates/service.yaml\n",
      "./templates/ingress-services.yaml\n",
      "./templates/service-sftp.yaml\n",
      "./templates/deployment.yaml\n",
      "./templates/configmap-php.yaml\n",
      "./templates/configmap-httpd.yaml\n",
      "./templates/configmap-init.yaml\n",
      "./templates/ingress-www.yaml\n",
      "./templates/secret.yaml\n",
      "./Chart.yaml\n",
      "./examples\n",
      "./examples/grav.yaml\n",
      "./examples/wordpress-php-ini.yaml\n",
      "./examples/joomla.yaml\n",
      "./examples/wordpress-ingress-ssl.yaml\n",
      "./examples/wordpress.yaml\n",
      "./examples/drupal.yaml\n",
      "./examples/nextcloud.yaml\n",
      "./examples/owncloud.yaml\n",
      "./.helmignore\n"
     ]
    }
   ],
   "source": [
    "cd ~/helm-charts/stable/lamp\n",
    "find ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `./templates` directory is the set of templated YAML files that are used to build the core LAMP setup. To highlight a couple: deployment.yaml set up an Apache server as a Deployment, pvc.yaml requests persistent storage (for the DB to use, called a PersistentVolumeClaim), configmap-init.yaml sets up a config file mounted into the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME:   mywordpress\n",
      "LAST DEPLOYED: Wed Oct  3 22:34:41 2018\n",
      "NAMESPACE: scotlandphp-XXXXX\n",
      "STATUS: DEPLOYED\n",
      "\n",
      "RESOURCES:\n",
      "==> v1/Secret\n",
      "NAME              TYPE    DATA  AGE\n",
      "mywordpress-lamp  Opaque  4     0s\n",
      "\n",
      "==> v1/ConfigMap\n",
      "NAME                    DATA  AGE\n",
      "mywordpress-lamp-httpd  3     0s\n",
      "mywordpress-lamp-php    2     0s\n",
      "\n",
      "==> v1/PersistentVolumeClaim\n",
      "NAME              STATUS   VOLUME    CAPACITY  ACCESS MODES  STORAGECLASS  AGE\n",
      "mywordpress-lamp  Pending  standard  0s\n",
      "\n",
      "==> v1/Service\n",
      "NAME              TYPE          CLUSTER-IP   EXTERNAL-IP  PORT(S)                      AGE\n",
      "mywordpress-lamp  LoadBalancer  10.15.242.8  <pending>    80:30366/TCP,3306:32237/TCP  0s\n",
      "\n",
      "==> v1beta1/Deployment\n",
      "NAME              DESIRED  CURRENT  UP-TO-DATE  AVAILABLE  AGE\n",
      "mywordpress-lamp  1        1        1           0          0s\n",
      "\n",
      "==> v1/Pod(related)\n",
      "NAME                               READY  STATUS   RESTARTS  AGE\n",
      "mywordpress-lamp-7b68d9d676-5wbtg  0/3    Pending  0         0s\n",
      "\n",
      "\n",
      "NOTES:\n",
      "INIT:\n",
      "      Please wait for all init containers to finish before connecting to\n",
      "      the charts services. This might take a few minutes depending on their\n",
      "      tasks.\n",
      "\n",
      "LOADBALANCER:\n",
      "      Please wait until the service has been routed to an IP address.\n",
      "      You can watch the status of by running 'kubectl get svc -w mywordpress-lamp'\n",
      "\n",
      "1. You can now connect to the following services:\n",
      "      export CHARTIP=$(kubectl get svc mywordpress-lamp --output=jsonpath={.status.loadBalancer.ingress..ip})\n",
      "\n",
      "      Main Site:\n",
      "        http://$CHARTIP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd ~/helm-charts/stable/lamp\n",
    "helm install . --values ./examples/wordpress.yaml --name mywordpress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just added some custom values in from `./examples/wordpress.yaml` to drop into the LAMP template. We could take a copy of this, fill in our own values and use it as a short per-deployment customization file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysql:\n",
      "  rootPassword: \"Root Password here...\"\n",
      "  user: wordpress\n",
      "  password: \"User Password here...\"\n",
      "  database: wordpress\n",
      "\n",
      "php:\n",
      "  repository: \"wordpress\"\n",
      "  tag: \"php7.1-fpm\"\n",
      "  envVars:\n",
      "  - name: WORDPRESS_DB_HOST\n",
      "    value: localhost\n",
      "  - name: WORDPRESS_DB_USER\n",
      "    value: wordpress\n",
      "  - name: WORDPRESS_DB_PASSWORD\n",
      "    value: \"User Password here...\"\n",
      "  - name: WORDPRESS_DB_DATABASE\n",
      "    value: wordpress\n"
     ]
    }
   ],
   "source": [
    "cat ~/helm-charts/stable/lamp/examples/wordpress.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME               TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)                       AGE\n",
      "mywordpress-lamp   LoadBalancer   10.15.242.8     35.230.157.0   80:30366/TCP,3306:32237/TCP   54s\n",
      "tiller-deploy      ClusterIP      10.15.252.217   <none>         44134/TCP                     8m\n"
     ]
    }
   ],
   "source": [
    "kubectl get services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal:  10.15.242.8\n",
      "External: http://35.230.157.0\n"
     ]
    }
   ],
   "source": [
    "echo \"Internal: \" $(kubectl get service mywordpress-lamp --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "echo \"External: http://$(kubectl get service mywordpress-lamp --output=jsonpath=\"{.status.loadBalancer.ingress[0].ip}\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "release \"mywordpress\" deleted\n"
     ]
    }
   ],
   "source": [
    "helm delete --purge mywordpress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Theory of PHP on K8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple app deployed on Kubernetes may look like the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIAGRAM of SIMPLE APP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the PHP case, there are a few caveats..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DIAGRAM of a PHP APP]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the second nginx container to provide HTTP access to PHP-FPM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Example Laravel App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/home/jovyan/buckram'...\n",
      "warning: redirecting to https://gitlab.com/flaxandteal/buckram-starter.git/\n",
      "remote: Enumerating objects: 28788, done.        \n",
      "remote: Counting objects: 100% (28788/28788), done.        \n",
      "remote: Compressing objects: 100% (10800/10800), done.        \n",
      "remote: Total 28788 (delta 17412), reused 28742 (delta 17378)        \n",
      "Receiving objects: 100% (28788/28788), 8.04 MiB | 9.96 MiB/s, done.\n",
      "Resolving deltas: 100% (17412/17412), done.\n"
     ]
    }
   ],
   "source": [
    "rm -rf ~/buckram; cd ~\n",
    "git clone https://gitlab.com/flaxandteal/buckram-starter ~/buckram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artisan.sh  dummy-values.yaml  sundry\t  values.yaml.example\n",
      "buckram     README.md\t       templates\n"
     ]
    }
   ],
   "source": [
    "cd ~/buckram/kubernetes\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a few tools for Kubernetes, in particular an example file for setting deployment-specific values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This is a template for the Kubernetes production secrets.\n",
      "# It is strongly recommended that you create and complete the\n",
      "# production.yaml file outside of the file tree\n",
      "laravel-nginx:\n",
      "  image:\n",
      "    repository: flaxandteal/buckram-nginx\n",
      "    tag: stable\n",
      "  ingress:\n",
      "    hostname: DNS.DOMAIN\n",
      "    annotations:\n",
      "      certmanager.k8s.io/cluster-issuer: letsencrypt-staging\n",
      "      kubernetes.io/ingress.class: nginx\n",
      "  laravel:\n",
      "    serverName: DNS.DOMAIN\n",
      "laravel-phpfpm:\n",
      "  image:\n",
      "    repository: flaxandteal/buckram-phpfpm\n",
      "    tag: stable\n",
      "  workerImage:\n",
      "    repository: flaxandteal/buckram-phpfpm\n",
      "    tag: stable\n",
      "  laravel:\n",
      "    app:\n",
      "      appKey: base64:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "      appUrl: \"https://DNS.DOMAIN\"\n",
      "      oauthPublicKey: OAUTH_PUBLIC_KEY_B64\n",
      "      oauthPrivateKey: OAUTH_PRIVATE_KEY_B64\n",
      "    mail:\n",
      "      username: \"mailuser\"\n",
      "      password: \"mailpass\"\n",
      "      host: \"smtp.host\"\n",
      "      port: \"25\"\n",
      "      fromAddress: \"from@example.com\"\n",
      "      fromName: \"From Name\"\n",
      "postgresql:\n",
      "  postgresPassword: xxxxxxxxx\n",
      "redis:\n",
      "  redisPassword: xxxxxxxxxx\n"
     ]
    }
   ],
   "source": [
    "cd ~/buckram/kubernetes\n",
    "cat values.yaml.example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quickstart, there is a basic Python tool in the `buckram` repository to autogenerate some values for these (`bookcloth`) - a sample output of this is in `dummy-values.yaml`. We will use this to demonstrate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go into the the Buckram Helm chart itself..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Unable to get an update from the \"local\" chart repository (http://127.0.0.1:8879/charts):\n",
      "\tGet http://127.0.0.1:8879/charts/index.yaml: dial tcp 127.0.0.1:8879: connect: connection refused\n",
      "...Successfully got an update from the \"stable\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n",
      "Saving 6 charts\n",
      "Deleting outdated charts\n",
      "2018/10/03 23:35:39 warning: destination for annotations is a table. Ignoring non-table value <nil>\n",
      "2018/10/03 23:35:39 warning: destination for annotations is a table. Ignoring non-table value <nil>\n",
      "Error: a release named buckram already exists.\n",
      "Run: helm ls --all buckram; to check the status of the release\n",
      "Or run: helm del --purge buckram; to delete it\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "cd ~/buckram/kubernetes/buckram\n",
    "helm dependencies update\n",
    "helm install . --name=buckram --values=../dummy-values.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "cd ~/buckram/kubernetes\n",
    "git status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in every type of deployment, we need to have specific custom settings for our own deployment. This answers several questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach:\n",
    "\n",
    "* **Where is our app code stored?**: In the final built images. During continuous integration (or manual building, for smaller scale), pre-prepared base images have the code added in. The built images are then tagged for that code version and pushed to a Docker image registry that the Kubernetes cluster can access.\n",
    "* **How do we keep our code secure?**: In this example, for simplicity we use the default base images, without custom app code - as such, they are pulled down from the public Docker Hub registry. However, there are private image registries within each cloud platform, e.g. AWS ECR, which Kubernetes can authenticate with to pull down images.\n",
    "* **What about secrets?**: In this particular approach, we use Kubernetes Secrets, which is simple but only a minimum bar (although, the default implementation is improving). Better practice is to use something like the Kubernetes Vault Operator, but this takes more care to set up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_None of these are hard and fast_. There are various approaches, with benefits and drawbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                             READY     STATUS      RESTARTS   AGE\n",
      "buckram-fluentd-79b748589f-bskhx                 1/1       Running     0          17m\n",
      "buckram-laravel-nginx-6ddb575b85-w86kv           1/1       Running     0          17m\n",
      "buckram-laravel-phpfpm-1538607360-dh8s4          0/1       Completed   0          2m\n",
      "buckram-laravel-phpfpm-1538607420-kzdzr          0/1       Completed   0          1m\n",
      "buckram-laravel-phpfpm-1538607480-mbtgb          0/1       Completed   0          20s\n",
      "buckram-laravel-phpfpm-5c9698bdd-k67hh           1/1       Running     0          9s\n",
      "buckram-laravel-phpfpm-worker-7dd798f458-mgz6b   1/1       Running     0          5m\n",
      "buckram-postgresql-0                             1/1       Running     0          17m\n",
      "buckram-redis-0                                  1/1       Running     0          17m\n",
      "fluent-bit-2z978                                 1/1       Running     0          17m\n",
      "fluent-bit-jkmbr                                 1/1       Running     0          17m\n",
      "fluent-bit-pd5pb                                 1/1       Running     0          17m\n",
      "tiller-deploy-d8db78b5b-68spl                    1/1       Running     0          29m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-run the above until it quietens down ^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2383    0  2383    0     0   1368      0 --:--:--  0:00:01 --:--:--  1367\n",
      "<!doctype html>\n",
      "<html lang=\"en\">\n",
      "    <head>\n",
      "        <meta charset=\"utf-8\">\n",
      "        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n",
      "\n",
      "        <title>Laravel</title>\n",
      "\n",
      "        <!-- Fonts -->\n"
     ]
    }
   ],
   "source": [
    "IP=$(kubectl get service buckram-laravel-nginx --output=jsonpath=\"{.spec.clusterIP}\")\n",
    "curl http://$IP | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([click here](/user/philtweir/notebooks/kubernetes-scotlandphp/visual-notebook.ipynb#Laravel) to get the rendered version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Work through the charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at what just started up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                             READY     STATUS      RESTARTS   AGE\n",
      "buckram-fluentd-79b748589f-bskhx                 1/1       Running     0          17m\n",
      "buckram-laravel-nginx-6ddb575b85-w86kv           1/1       Running     0          17m\n",
      "buckram-laravel-phpfpm-1538607360-dh8s4          0/1       Completed   0          2m\n",
      "buckram-laravel-phpfpm-1538607420-kzdzr          0/1       Completed   0          1m\n",
      "buckram-laravel-phpfpm-1538607480-mbtgb          0/1       Completed   0          45s\n",
      "buckram-laravel-phpfpm-5c9698bdd-k67hh           1/1       Running     0          34s\n",
      "buckram-laravel-phpfpm-worker-7dd798f458-mgz6b   1/1       Running     0          6m\n",
      "buckram-postgresql-0                             1/1       Running     0          17m\n",
      "buckram-redis-0                                  1/1       Running     0          17m\n",
      "fluent-bit-2z978                                 1/1       Running     0          17m\n",
      "fluent-bit-jkmbr                                 1/1       Running     0          17m\n",
      "fluent-bit-pd5pb                                 1/1       Running     0          17m\n",
      "tiller-deploy-d8db78b5b-68spl                    1/1       Running     0          30m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above the list of pods is, roughly, the list of processes. There should be some familiar faces there: several PHP-FPM pods, nginx, PostgreSQL and redis.\n",
    "\n",
    "Alongside them, you can see fluent-bit - it will forward logs from the processes to a single aggregated destination. Between this and redis (queueing, caching, sessions), the PHP-FPM pod does not need to have any state, easing scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By telling PHP to send to stdout by default, we find that the logs from this Pod are indeed the PHP logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03-Oct-2018 22:58:23] NOTICE: fpm is running, pid 1\n",
      "[03-Oct-2018 22:58:23] NOTICE: ready to handle connections\n",
      "10.12.1.13 -  03/Oct/2018:22:58:27 +0000 \"GET /index.php\" 200\n",
      "10.12.1.13 -  03/Oct/2018:22:58:35 +0000 \"GET /index.php\" 200\n"
     ]
    }
   ],
   "source": [
    "PHP_POD=$(kubectl get pods --selector=tier=middle -o=name)\n",
    "kubectl logs $PHP_POD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach also simplified life for log aggregation, where logs can be gathered from the stdout/stderr of the various Pods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Break\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gitlab CI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_20 min_ (-> 1:50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is Gitlab CI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gitlab continuous integration (CI) provides us with an easy way to go from local development to built images. To follow along, you will need to have [your own Gitlab account or sign up](https://gitlab.com/users/sign_in), or can look through the [details of the pipeline](https://gitlab.com/flaxandteal/buckram-demo/pipelines) of the existing demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to use your own account, then you [should fork](https://gitlab.com/flaxandteal/buckram-demo/forks/new) a copy. You can clone it down here, or on your own machine/VM to make it easier to experiment. If you want to use your fork in this notebook, change the Gitlab URL below to your fork's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'buckram-demo'...\n",
      "warning: redirecting to https://gitlab.com/phil.weir/buckram-demo.git/\n",
      "remote: Enumerating objects: 145, done.        \n",
      "remote: Counting objects: 100% (145/145), done.        \n",
      "remote: Compressing objects: 100% (106/106), done.        \n",
      "remote: Total 145 (delta 22), reused 137 (delta 19)        \n",
      "Receiving objects: 100% (145/145), 197.99 KiB | 765.00 KiB/s, done.\n",
      "Resolving deltas: 100% (22/22), done.\n"
     ]
    }
   ],
   "source": [
    "cd ~\n",
    "rm -rf buckram-demo\n",
    "git clone https://gitlab.com/phil.weir/buckram-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository has only a couple of minor differences from the usual `composer create-project laravel` output, namely, running composer (after adding behat), a `.gitlab-ci.yml` file and a submodule containing the buckram content, which is in an `infrastructure` subfolder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule 'infrastructure' (https://gitlab.com/flaxandteal/buckram) registered for path 'infrastructure'\n",
      "Cloning into '/home/jovyan/buckram-demo/infrastructure'...\n",
      "warning: redirecting to https://gitlab.com/flaxandteal/buckram.git/\n",
      "Submodule path 'infrastructure': checked out '53ab820046e457061b6401c6e1e3ef6bec2e55b5'\n"
     ]
    }
   ],
   "source": [
    "cd ~/buckram-demo\n",
    "git submodule update --init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our Buckram repository is not necessary for any of this, but is simply a way of bringing together common features, such as CI templates, Helm charts and config generation, which you could do independently. They are useful, accessible examples for a smallish context, but once familiar, you will find a number of features you will wish to add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " create mode 100644 .gitmodules\n",
      " create mode 100644 features/bootstrap/FeatureContext.php\n",
      " create mode 160000 infrastructure\n",
      " delete mode 100644 tests/Feature/ExampleTest.php\n"
     ]
    }
   ],
   "source": [
    "cd ~/buckram-demo\n",
    "git diff $(git rev-list --max-parents=0 HEAD)..HEAD --summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we can take a look at the `.gitlab-ci.yml` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: docker:latest\n",
      "\n",
      "variables:\n",
      "  CONTAINER_NGINX_IMAGE: $CI_REGISTRY_IMAGE:nginx-$CI_PIPELINE_ID\n",
      "  CONTAINER_NGINX_RELEASE_IMAGE: $CI_REGISTRY_IMAGE:nginx-latest\n",
      "  CONTAINER_PHPFPM_IMAGE: $CI_REGISTRY_IMAGE:phpfpm-$CI_PIPELINE_ID\n",
      "  CONTAINER_PHPFPM_RELEASE_IMAGE: $CI_REGISTRY_IMAGE:phpfpm-latest\n",
      "  COMPOSER_CACHE_DIR: /cache\n",
      "  DOCKER_DRIVER: overlay\n",
      "\n",
      "stages:\n",
      "- composer\n",
      "- build\n",
      "- test\n",
      "- release\n",
      "- deploy\n",
      "\n",
      "services:\n",
      "- docker:dind\n",
      "\n",
      "before_script:\n",
      "  - docker login -u gitlab-ci-token -p $CI_BUILD_TOKEN registry.gitlab.com\n",
      "\n",
      "composer:\n",
      "  stage: composer\n",
      "  before_script:\n",
      "  - echo \"Building PHP dependencies\"\n",
      "  image: composer\n",
      "  script:\n",
      "  - composer install\n",
      "  artifacts:\n",
      "    paths:\n",
      "    - vendor\n",
      "    - bootstrap/cache\n",
      "    - bootstrap/autoload.php\n",
      "    - composer.lock\n",
      "\n",
      "build:\n",
      "  stage: build\n",
      "  variables:\n",
      "    GIT_SUBMODULE_STRATEGY: recursive\n",
      "  script:\n",
      "  - chown -R 33 storage/logs bootstrap/cache\n",
      "  - docker build -f infrastructure/containers/nginx/Dockerfile -t $CONTAINER_NGINX_IMAGE .\n",
      "  - docker build -f infrastructure/containers/phpfpm/Dockerfile -t $CONTAINER_PHPFPM_IMAGE .\n",
      "  - docker push $CONTAINER_NGINX_IMAGE\n",
      "  - docker push $CONTAINER_PHPFPM_IMAGE\n",
      "  dependencies:\n",
      "  - composer\n",
      "\n",
      "test:\n",
      "  stage: test\n",
      "  script:\n",
      "  - docker run -t $CONTAINER_PHPFPM_IMAGE sh -c \"curl -L -o phpunit https://phar.phpunit.de/phpunit-7.2.phar && chmod +x phpunit && ./phpunit\"\n",
      "  - docker run -t $CONTAINER_PHPFPM_IMAGE sh -c \"curl -L -o behat https://github.com/Behat/Behat/releases/download/v3.3.0/behat.phar && chmod +x behat && ./behat\"\n",
      "  # - docker run --entrypoint vendor/behat/behat/bin/behat $CONTAINER_PHPFPM_IMAGE\n",
      "\n",
      "release:\n",
      "  stage: release\n",
      "  script:\n",
      "  # NGINX\n",
      "  - docker pull $CONTAINER_NGINX_IMAGE\n",
      "  - docker tag $CONTAINER_NGINX_IMAGE $CONTAINER_NGINX_RELEASE_IMAGE\n",
      "  - docker push $CONTAINER_NGINX_RELEASE_IMAGE\n",
      "  # PHPFPM\n",
      "  - docker pull $CONTAINER_PHPFPM_IMAGE\n",
      "  - docker tag $CONTAINER_PHPFPM_IMAGE $CONTAINER_PHPFPM_RELEASE_IMAGE\n",
      "  - docker push $CONTAINER_PHPFPM_RELEASE_IMAGE\n",
      "  only:\n",
      "  - master\n",
      "  - development\n"
     ]
    }
   ],
   "source": [
    "cat .gitlab-ci.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular approach, for simplicity, both the nginx and PHP containers end up with the build code - a nicer tactic would be to have any static assets deployed separately, so that nginx only needs to proxy requests to PHP-FPM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first few sections are configuration, essentially preparing the environment. The following, `composer`, `build` and `release` steps are the sequence the CI will follow. The first runs composer (it does this inside the official composer Docker image), the second combines these with our pre-prepared base images. For more detail on the PHP-FPM setup used, have a look at `./infrastructure/containers/phpfpm` (while it starts from the official base it has, for instance, ext-redis added in)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Buckram repository, there is a template `gitlab-ci.yml` - while it isn't useful for our demo, you will see this has an additional `deploy-dev` section for deploying directly to a Kubernetes cluster. Over the last year or two, Gitlab's direct deployment integration for Kubernetes on Google has come on, so you may want to look at this option too. However, it may be illustrative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deploy_dev:\n",
      "  image: google/cloud-sdk:162.0.0\n",
      "  before_script:\n",
      "  - kubectl config set-cluster \"$CI_PROJECT_ID\" --server=\"$KUBE_URL\" --certificate-authority=\"$KUBE_CA_PEM_FILE\"\n",
      "  - kubectl config set-credentials \"$CI_PROJECT_ID\" --token=\"$KUBE_TOKEN\"\n",
      "  - kubectl config set-context \"$CI_PROJECT_ID\" --cluster=\"$CI_PROJECT_ID\" --user=\"$CI_PROJECT_ID\" --namespace=\"$KUBE_NAMESPACE\"\n",
      "  - kubectl config use-context \"$CI_PROJECT_ID\"\n",
      "  stage: deploy\n",
      "  script:\n",
      "  - >-\n",
      "    kubectl patch cronjob.v2alpha1.batch $CI_ENVIRONMENT_SLUG-laravel-artisan\n",
      "      -p \"{\n",
      "        \\\"spec\\\": {\n",
      "          \\\"jobTemplate\\\": {\n",
      "            \\\"spec\\\": {\n",
      "              \\\"template\\\": {\n",
      "                \\\"spec\\\": {\n",
      "                  \\\"containers\\\": [\n",
      "                    {\n",
      "                      \\\"name\\\": \\\"$CI_ENVIRONMENT_SLUG-laravel-scheduler\\\",\n",
      "                      \\\"image\\\": \\\"$AWS_ECR_URI:phpfpm-$CI_PIPELINE_ID\\\"\n",
      "                    }\n",
      "                  ]\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\"\n",
      "  - kubectl set image deployment/$CI_ENVIRONMENT_SLUG-laravel-artisan laravel-artisan-worker=$AWS_ECR_URI:phpfpm-$CI_PIPELINE_ID\n",
      "  - kubectl set image deployment/$CI_ENVIRONMENT_SLUG-laravel-nginx nginx=$AWS_ECR_URI:nginx-$CI_PIPELINE_ID\n",
      "  - kubectl set image deployment/$CI_ENVIRONMENT_SLUG-laravel-phpfpm laravel-phpfpm=$AWS_ECR_URI:phpfpm-$CI_PIPELINE_ID\n",
      "  environment:\n",
      "    name: dev\n",
      "    url: http://$CI_ENVIRONMENT_SLUG.$CI_TARGET_DOMAIN\n",
      "  only:\n",
      "  - development\n",
      "  dependencies: []\n"
     ]
    }
   ],
   "source": [
    "grep -A 100 'deploy_dev:' ~/buckram/gitlab-ci/gitlab-ci.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Kubernetes has Role Based Authorization Control (RBAC), so we can create a user with deployment credentials and Gitlab will ensure our CI user receives them. We use a Docker image with `kubectl` to run these commands. It would be possible do this via `curl` calls also, to the Kubernetes API. A particular benefit of Gitlab-CI is that it can be run internally, or even _on_ Kubernetes, while being usable as a free hosted service to experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not the only option, however - Bitbucket now has a similar set-up. Jenkins, CircleCI and others can provide these types of pipeline also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the CI steps show some of the Docker commands that could be run locally, if you wanted to get the hang of Docker in a manual way, building images and pushing them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test step lets us run `behat` and `phptest`, by default, when any branch is pushed. Gitlab will notify you of any errors, and can trigger a merge based on its outcome, for instance. Code coverage and linting could similarly be added here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The magic of Gitlab-CI is that it will start working as soon as receives a commit with a valid `.gitlab-ci.yml` file in the root directory (note the first dot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                </div>\n",
      "            @endif\n",
      "\n",
      "            <div class=\"content\">\n",
      "                <div class=\"title m-b-md\">\n",
      "                    LaravelTest\n",
      "                </div>\n",
      "\n",
      "                <div class=\"links\">\n",
      "                    <a href=\"https://laravel.com/docs\">Documentation</a>\n",
      "                    <a href=\"https://laracasts.com\">Laracasts</a>\n"
     ]
    }
   ],
   "source": [
    "grep -C 5 ' Laravel' resources/views/welcome.blade.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have taken a fork, then you can try the following (otherwise, keep an eye on my fork's [pipeline's page](https://gitlab.com/flaxandteal/buckram-demo/pipelines)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gitlab.com/USERNAME/buckram-demo/blob/master/resources/views/welcome.blade.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(change the USERNAME to your own). Edit the page (Edit button on upper right), perhaps changing the word Laravel on line 82 to something else. This is equivalent to making a manual change and pushing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Pipelines page (under CI/CD on the left-hand menu), you will see the progress of the building through the stages. Gitlab uses its own container registry to manage the images back and forward, and some handy free CI runners. Running your own CI runner is easy, and generally much faster per run, not to mention allowing you to control the process. Another key benefit is that you can also cache composer downloads and Docker images between steps and runs - although many prefer to take the extra time to pull fresh from the package repository on each build anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note on frontend: if using little frontend code or a tightly-integrated frontend framework in the Laravel codebase, then this may be sufficient. Most of our work is with API-based backends and self-contained VueJS single-page applications. Our approach is to run the necessary CI steps on the frontend repository, producing a JS/CSS tarball that is released to S3, and trigger a new backend pipeline run from the final frontend step, to pull down and build a fresh final set of Docker images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command manually updates the PHP-FPM image to point to the newly build Gitlab one (NB: only the web-serving one, not the queue worker or cronjob). You should swap the `phil.weir` and number at the end for your username and pipeline number, respectively.\n",
    "\n",
    "_Make sure you don't confuse the pipeline and job numbers_, the pipeline number will be shown on the Pipelines page, usually starting with a hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.extensions/buckram-laravel-phpfpm image updated\n"
     ]
    }
   ],
   "source": [
    "kubectl set image deployment/buckram-laravel-phpfpm laravel-phpfpm=registry.gitlab.com/phil.weir/buckram-demo:phpfpm-31946481"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                             READY     STATUS    RESTARTS   AGE\n",
      "buckram-laravel-phpfpm-66568bdc97-pvv58          1/1       Running   0          13s\n",
      "buckram-laravel-phpfpm-worker-7dd798f458-mgz6b   1/1       Running   0          1h\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods --selector=app=buckram-laravel-phpfpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the above command shows \"Status: running\", then try the Laravel call in the [other notebook](/user/philtweir/notebooks/kubernetes-scotlandphp/visual-notebook.ipynb#Laravel) again - you should see the altered welcome page from your newly built image!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes provides some useful tools for managing roll-out. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployments \"buckram-fluentd\"\n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "\n",
      "deployments \"buckram-laravel-nginx\"\n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "\n",
      "deployments \"buckram-laravel-phpfpm\"\n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "2         <none>\n",
      "3         <none>\n",
      "\n",
      "deployments \"buckram-laravel-phpfpm-worker\"\n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "2         <none>\n",
      "\n",
      "deployments \"tiller-deploy\"\n",
      "REVISION  CHANGE-CAUSE\n",
      "1         <none>\n",
      "2         <none>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl rollout history deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see how many revisions have been made to your deployments - you should see 3, one for each of fluentd, nginx and phpfpm-worker, all with 1 revision, and a fourth for phpfpm, with an additional revision (assuming you correctly deleted the earlier experiments!). This additional revision represents the action of changing the Docker image used, above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can roll back deployments, you can require a certain minimum number of live pods at any time during the rolling update, or even decide where new Pods are scheduled on the underlying VMs/systems (termed Nodes). Kubernetes has concepts of liveness and readiness probes, so for some types of deployment, it can spot when Pods are functional or not. In addition, this allows it to undertake one of the most fundamental aspects of orchestration, replacing Pods when they become unresponsive or die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artisan and Jobs\n",
    "(moved from end?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_20 min_ (-> 2:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will address a few of the key features of Laravel, and PHP frameworks in general, here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Worker process & Redis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's already been pointed out that there is an artisan Pod running - phpfpm-worker. For those unfamiliar, `artisan` is Laravel's command-line tool, providing console control for one-off tasks, but also entrypoints for worker processes and the task scheduler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In normal usage, getting an artisan queue worker process running involves:\n",
    "\n",
    "    php artisan queue:work\n",
    "\n",
    "You may wish to use this to, for instance, submit emails to a sending service or call batch services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, it becomes part of the `development-artisan.yaml` Chart file (see the arrays around line 25):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1\tapiVersion: extensions/v1beta1\n",
      "     2\tkind: Deployment\n",
      "     3\tmetadata:\n",
      "     4\t  name: {{ template \"fullname\" . }}-worker\n",
      "     5\t  labels:\n",
      "     6\t    chart: \"{{ .Chart.Name }}-{{ .Chart.Version | replace \"+\" \"_\" }}\"\n",
      "     7\t    release: \"{{ .Release.Name }}\"\n",
      "     8\t    heritage: \"{{ .Release.Service }}\"\n",
      "     9\tspec:\n",
      "    10\t  replicas: {{ .Values.replicaCount }}\n",
      "    11\t  template:\n",
      "    12\t    metadata:\n",
      "    13\t      labels:\n",
      "    14\t        app: {{ template \"fullname\" . }}\n",
      "    15\t        tier: \"backend\"\n",
      "    16\t    spec:\n",
      "    17\t{{- if .Values.workerImage.secrets }}\n",
      "    18\t      imagePullSecrets:\n",
      "    19\t      - name: {{ .Values.workerImage.secrets }}\n",
      "    20\t{{- end }}\n",
      "    21\t      containers:\n",
      "    22\t      - name: {{ .Chart.Name }}-worker\n",
      "    23\t        command:\n",
      "    24\t        - php\n",
      "    25\t        - /var/www/app/artisan\n",
      "    26\t        args:\n",
      "    27\t        - queue:work\n",
      "    28\t{{- if .Values.laravel.queue.tries }}\n",
      "    29\t        - --tries={{ .Values.laravel.queue.tries }}\n",
      "    30\t{{- end }}\n",
      "    31\t        image: \"{{ .Values.workerImage.repository }}:{{ .Values.workerImage.tag }}\"\n",
      "    32\t        imagePullPolicy: {{ .Values.workerImage.pullPolicy }}\n",
      "    33\t        envFrom:\n",
      "    34\t        - configMapRef:\n",
      "    35\t            name: {{ template \"fullname\" . }}-env\n",
      "    36\t        env:\n",
      "    37\t        - name: APP_KEY\n",
      "    38\t          valueFrom:\n",
      "    39\t            secretKeyRef:\n",
      "    40\t              key: app-key\n",
      "    41\t              name: {{ template \"fullname\" . }}-env\n",
      "    42\t{{- if .Values.laravel.mail.sesKey }}\n",
      "    43\t        - name: SES_SECRET\n",
      "    44\t          valueFrom:\n",
      "    45\t            secretKeyRef:\n",
      "    46\t              key: ses-secret\n",
      "    47\t              name: {{ template \"fullname\" . }}-env\n",
      "    48\t{{- end }}\n",
      "    49\t        - name: MAIL_PASSWORD\n",
      "    50\t          valueFrom:\n",
      "    51\t            secretKeyRef:\n",
      "    52\t              key: mail-password\n",
      "    53\t              name: {{ template \"fullname\" . }}-env\n",
      "    54\t        - name: DB_PASSWORD\n",
      "    55\t          valueFrom:\n",
      "    56\t            secretKeyRef:\n",
      "    57\t              key: postgres-password\n",
      "    58\t              name: \"{{ .Release.Name }}-postgresql\"\n",
      "    59\t        - name: REDIS_PASSWORD\n",
      "    60\t          valueFrom:\n",
      "    61\t            secretKeyRef:\n",
      "    62\t              key: redis-password\n",
      "    63\t              name: \"{{ .Release.Name }}-redis\"\n",
      "    64\t        volumeMounts:\n",
      "    65\t        - mountPath: /var/www/app/secrets\n",
      "    66\t          name: keys\n",
      "    67\t          items:\n",
      "    68\t          - key: oauth-public.key\n",
      "    69\t            path: oauth-public.key\n",
      "    70\t          - key: oauth-private.key\n",
      "    71\t            path: oauth-private.key\n",
      "    72\t        - name: laravel-phpfpm-config\n",
      "    73\t          mountPath: /usr/local/etc/php-fpm.d/www.conf\n",
      "    74\t          subPath: www.conf\n",
      "    75\t        resources:\n",
      "    76\t{{ toYaml .Values.resources | indent 12 }}\n",
      "    77\t      volumes:\n",
      "    78\t      - name: keys\n",
      "    79\t        secret:\n",
      "    80\t          secretName: {{ template \"fullname\" . }}\n",
      "    81\t      - name: laravel-phpfpm-config\n",
      "    82\t        configMap:\n",
      "    83\t          name: {{ template \"fullname\" . }}\n"
     ]
    }
   ],
   "source": [
    "cat ~/buckram/kubernetes/buckram/subcharts/laravel-phpfpm/templates/deployment-artisan.yaml | nl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can contrast the in situ version, by pulling down the definition of the live pod, created from this template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "kind: Pod\n",
      "metadata:\n",
      "  creationTimestamp: 2018-10-03T22:52:36Z\n",
      "  generateName: buckram-laravel-phpfpm-worker-7dd798f458-\n",
      "  labels:\n",
      "    app: buckram-laravel-phpfpm\n",
      "    pod-template-hash: \"3883549014\"\n",
      "    tier: backend\n",
      "  name: buckram-laravel-phpfpm-worker-7dd798f458-mgz6b\n",
      "  namespace: scotlandphp-XXXXX\n",
      "  ownerReferences:\n",
      "  - apiVersion: extensions/v1beta1\n",
      "    blockOwnerDeletion: true\n",
      "    controller: true\n",
      "    kind: ReplicaSet\n",
      "    name: buckram-laravel-phpfpm-worker-7dd798f458\n",
      "    uid: 058d907e-c75f-11e8-b213-42010a9a007a\n",
      "  resourceVersion: \"15726\"\n",
      "  selfLink: /api/v1/namespaces/scotlandphp-XXXXX/pods/buckram-laravel-phpfpm-worker-7dd798f458-mgz6b\n",
      "  uid: 0592eb2a-c75f-11e8-b213-42010a9a007a\n",
      "spec:\n",
      "  containers:\n",
      "  - args:\n",
      "    - queue:work\n",
      "    - --tries=3\n",
      "    command:\n",
      "    - php\n",
      "    - /var/www/app/artisan\n",
      "    env:\n",
      "    - name: APP_KEY\n",
      "      valueFrom:\n",
      "        secretKeyRef:\n",
      "          key: app-key\n",
      "          name: buckram-laravel-phpfpm-env\n",
      "    - name: MAIL_PASSWORD\n",
      "      valueFrom:\n",
      "        secretKeyRef:\n",
      "          key: mail-password\n",
      "          name: buckram-laravel-phpfpm-env\n",
      "    - name: DB_PASSWORD\n",
      "      valueFrom:\n",
      "        secretKeyRef:\n",
      "          key: postgres-password\n",
      "          name: buckram-postgresql\n",
      "    - name: REDIS_PASSWORD\n",
      "      valueFrom:\n",
      "        secretKeyRef:\n",
      "          key: redis-password\n",
      "          name: buckram-redis\n",
      "    envFrom:\n",
      "    - configMapRef:\n",
      "        name: buckram-laravel-phpfpm-env\n",
      "    image: flaxandteal/buckram-phpfpm:latest\n",
      "    imagePullPolicy: Always\n",
      "    name: laravel-phpfpm-worker\n",
      "    resources:\n",
      "      limits:\n",
      "        cpu: 100m\n",
      "        memory: 256Mi\n",
      "      requests:\n",
      "        cpu: 100m\n",
      "        memory: 256Mi\n",
      "    terminationMessagePath: /dev/termination-log\n",
      "    terminationMessagePolicy: File\n",
      "    volumeMounts:\n",
      "    - mountPath: /var/www/app/secrets\n",
      "      name: keys\n",
      "    - mountPath: /usr/local/etc/php-fpm.d/www.conf\n",
      "      name: laravel-phpfpm-config\n",
      "      subPath: www.conf\n",
      "    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n",
      "      name: default-token-k7jts\n",
      "      readOnly: true\n",
      "  dnsPolicy: ClusterFirst\n",
      "  nodeName: gke-scotlandphp-3-default-pool-32254843-3rbk\n",
      "  restartPolicy: Always\n",
      "  schedulerName: default-scheduler\n",
      "  securityContext: {}\n",
      "  serviceAccount: default\n",
      "  serviceAccountName: default\n",
      "  terminationGracePeriodSeconds: 30\n",
      "  tolerations:\n",
      "  - effect: NoExecute\n",
      "    key: node.kubernetes.io/not-ready\n",
      "    operator: Exists\n",
      "    tolerationSeconds: 300\n",
      "  - effect: NoExecute\n",
      "    key: node.kubernetes.io/unreachable\n",
      "    operator: Exists\n",
      "    tolerationSeconds: 300\n",
      "  volumes:\n",
      "  - name: keys\n",
      "    secret:\n",
      "      defaultMode: 420\n",
      "      secretName: buckram-laravel-phpfpm\n",
      "  - configMap:\n",
      "      defaultMode: 420\n",
      "      name: buckram-laravel-phpfpm\n",
      "    name: laravel-phpfpm-config\n",
      "  - name: default-token-k7jts\n",
      "    secret:\n",
      "      defaultMode: 420\n",
      "      secretName: default-token-k7jts\n",
      "status:\n",
      "  conditions:\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: 2018-10-03T22:52:36Z\n",
      "    status: \"True\"\n",
      "    type: Initialized\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: 2018-10-03T22:52:45Z\n",
      "    status: \"True\"\n",
      "    type: Ready\n",
      "  - lastProbeTime: null\n",
      "    lastTransitionTime: 2018-10-03T22:52:36Z\n",
      "    status: \"True\"\n",
      "    type: PodScheduled\n",
      "  containerStatuses:\n",
      "  - containerID: docker://3732c5ef31634a33fc2988c917872771dfbc7b970c72ee0a3d765c017d85b549\n",
      "    image: flaxandteal/buckram-phpfpm:latest\n",
      "    imageID: docker-pullable://flaxandteal/buckram-phpfpm@sha256:81d1476e94acd935e1e4f695a9ae4271d01aee320aeed72ce3579c7fb9f3f43e\n",
      "    lastState: {}\n",
      "    name: laravel-phpfpm-worker\n",
      "    ready: true\n",
      "    restartCount: 0\n",
      "    state:\n",
      "      running:\n",
      "        startedAt: 2018-10-03T22:52:44Z\n",
      "  hostIP: 10.154.0.4\n",
      "  phase: Running\n",
      "  podIP: 10.12.0.30\n",
      "  qosClass: Guaranteed\n",
      "  startTime: 2018-10-03T22:52:36Z\n"
     ]
    }
   ],
   "source": [
    "WORKER_POD=$(kubectl get pods --selector=tier=backend -o=name)\n",
    "kubectl get $WORKER_POD -o=yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As running Redis in the cluster is an easy starting point, we use it to handle the queues (Laravel has Redis as an in-built option):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nami    INFO  Initializing redis\n",
      "redis   INFO \n",
      "redis   INFO  ########################################################################\n",
      "redis   INFO   Installation parameters for redis:\n",
      "redis   INFO     Password: **********\n",
      "redis   INFO   (Passwords are not shown for security reasons)\n",
      "redis   INFO  ########################################################################\n",
      "redis   INFO \n",
      "nami    INFO  redis successfully initialized\n",
      "Starting application ...\n",
      "\n",
      "  *** Welcome to the redis image ***\n",
      "  *** Brought to you by Bitnami ***\n",
      "  *** More information: https://github.com/bitnami/bitnami-docker-redis ***\n",
      "  *** Issues: https://github.com/bitnami/bitnami-docker-redis/issues ***\n",
      "\n",
      " |    `-._`-._        _.-'_.-'    |                                  \n",
      "  `-._    `-._`-.__.-'_.-'    _.-'                                   \n",
      "      `-._    `-.__.-'    _.-'                                       \n",
      "          `-._        _.-'                                           \n",
      "              `-.__.-'                                               \n",
      "\n",
      "62:M 03 Oct 22:41:51.742 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n",
      "62:M 03 Oct 22:41:51.742 # Server started, Redis version 3.2.6\n",
      "62:M 03 Oct 22:41:51.742 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n",
      "62:M 03 Oct 22:41:51.742 * The server is now ready to accept connections on port 6379\n",
      "62:M 03 Oct 22:58:28.980 * 1 changes in 900 seconds. Saving...\n",
      "62:M 03 Oct 22:58:28.981 * Background saving started by pid 1005\n",
      "1005:C 03 Oct 22:58:29.003 * DB saved on disk\n",
      "1005:C 03 Oct 22:58:29.004 * RDB: 0 MB of memory used by copy-on-write\n",
      "62:M 03 Oct 22:58:29.082 * Background saving terminated with success\n"
     ]
    }
   ],
   "source": [
    "kubectl logs $(kubectl get pods --selector=app=buckram-redis -o=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-off Jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cronjobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make scheduled tasks work, we use the Kubernetes concept of Cronjobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                     SCHEDULE    SUSPEND   ACTIVE    LAST SCHEDULE   AGE\n",
      "buckram-laravel-phpfpm   * * * * *   False     0         32s             25m\n"
     ]
    }
   ],
   "source": [
    "kubectl get cronjobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see this uses a similar format to traditional cron schedules. As with the normal Laravel approach, we set this to run an artisan job every minute (`php artisan schedule:run`), and Laravel's scheduler will decide whether any of the PHP-defined tasks are due to get kicked off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite configurable - we can say how many completed Pods we want to keep, for diagnostics, and how many failed ones, how long we give them to start up, and how many attempts each will get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Running artisan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of a broader concept of Jobs. These are requests to schedule a one-off Pod to do some task or other. Kubernetes' Cronjobs are really just creating a \"Job\" each minute from a template. Jobs in general provide a reasonable way to run one-off artisan tasks also.\n",
    "\n",
    "At present, we use a barebones script to simplify this process - running it creates a fresh new Job (from the template as the Cronjob, as it happens), and sets the internal artisan arguments to whichever command line flags we pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job.batch/laravel-job-1538607998 created\n",
      "Flag --show-all has been deprecated, will be removed in an upcoming release\n",
      "Found pod: laravel-job-1538607998-n94kw\n",
      "Error from server (BadRequest): container \"laravel-phpfpm-scheduler\" in pod \"laravel-job-1538607998-n94kw\" is waiting to start: ContainerCreating\n",
      "Error from server (BadRequest): container \"laravel-phpfpm-scheduler\" in pod \"laravel-job-1538607998-n94kw\" is waiting to start: ContainerCreating\n",
      "+--------+----------+----------+------+---------+--------------+\n",
      "| Domain | Method   | URI      | Name | Action  | Middleware   |\n",
      "+--------+----------+----------+------+---------+--------------+\n",
      "|        | GET|HEAD | /        |      | Closure | web          |\n",
      "|        | GET|HEAD | api/user |      | Closure | api,auth:api |\n",
      "+--------+----------+----------+------+---------+--------------+\n"
     ]
    }
   ],
   "source": [
    "cd ~/buckram/kubernetes\n",
    "./artisan.sh route:list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will get a few Errors as it starts up (ending \"ContainerCreating\"), but it should follow the Pod's logs once the Pod has started. Note that this approach is non-interactive (in fact, asynchronous)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                DESIRED   SUCCESSFUL   AGE\n",
      "buckram-laravel-phpfpm-1538607840   1         1            2m\n",
      "buckram-laravel-phpfpm-1538607900   1         1            1m\n",
      "buckram-laravel-phpfpm-1538607960   1         1            42s\n",
      "laravel-job-1538607998              1         1            9s\n"
     ]
    }
   ],
   "source": [
    "kubectl get jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you should see a range of Jobs that have been run, including your manual one as \"laravel-job\" and a timestamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Managing Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_20 min_ (-> 2:30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in any other setting, you will want to have more than one app platform running at once: usually for development, staging and production; or perhaps blue/green deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gitlab provide tools to help manage separate environments, along with Kubernetes - some of that is quite tied to Google Kubernetes Engine, but some is platform agnostic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a separate Helm `values.yaml` file may be sufficient to give, e.g. a dev and staging cluster. You may be happy enough to have these both on the same Kubernetes cluster, treating it as an infrastructure provider, as long as they are namespaced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubernetes does provide namespacing - the divisions are being hardened at each version, and it is possible to apply resource usage policies, user role policies and network segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                      READY     STATUS    RESTARTS   AGE\n",
      "event-exporter-v0.2.1-5f5b89fcc8-7lzcn                    2/2       Running   0          2h\n",
      "fluentd-gcp-scaler-7c5db745fc-l8srn                       1/1       Running   0          2h\n",
      "fluentd-gcp-v3.1.0-8pssr                                  2/2       Running   0          2h\n",
      "fluentd-gcp-v3.1.0-hftfn                                  2/2       Running   0          2h\n",
      "fluentd-gcp-v3.1.0-vcj6p                                  2/2       Running   0          2h\n",
      "heapster-v1.5.3-6795f54f76-8jhlg                          3/3       Running   0          2h\n",
      "kube-dns-788979dc8f-khnmc                                 4/4       Running   0          2h\n",
      "kube-dns-788979dc8f-vrcrd                                 4/4       Running   0          2h\n",
      "kube-dns-autoscaler-79b4b844b9-nwd9t                      1/1       Running   0          2h\n",
      "kube-proxy-gke-scotlandphp-3-default-pool-32254843-3rbk   1/1       Running   0          2h\n",
      "kube-proxy-gke-scotlandphp-3-default-pool-32254843-4mdz   1/1       Running   0          2h\n",
      "kube-proxy-gke-scotlandphp-3-default-pool-32254843-b3hp   1/1       Running   0          2h\n",
      "l7-default-backend-5d5b9874d5-hl5fs                       1/1       Running   0          2h\n",
      "metrics-server-v0.2.1-7486f5bd67-xtqjd                    2/2       Running   0          2h\n",
      "tiller-deploy-5c688d5f9b-8nv92                            1/1       Running   0          1h\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods -n kube-system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that there are a number of Pods doing more fundamental things than nginx - providing internal DNS, managing Helm's requests, handling Kubernetes API calls, running controller loops. These are all in the `kube-system` namespace by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kubectl works on a concept of users, contexts and clusters. You might not have spotted yet, but Kubernetes does not have a concept of user accounts, per se. It does have a concept of authentication, which can be by certificates, tokens, OpenID Connect, for example, and authorization Roles, which are bound to a username matching a RoleBinding rule when it successfully authenticates. However, no separate \"User\" object exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contexts allow you to specify a user, a namespace and a cluster to work with by default. Switching contexts allows you to easily manage multiple clusters and namespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT   NAME              CLUSTER           AUTHINFO       NAMESPACE\n",
      "*         jupyter-cluster   jupyter-cluster   jupyter-user   scotlandphp-XXXXX\n"
     ]
    }
   ],
   "source": [
    "kubectl config get-contexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `~/buckram/docs` folder is a script, `update_cluster_to_ci_build_ref.sh`, to update one context from another - this can be very handy for manual promotion, where you want to have specific controls in place to control access to the update workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Health, Logging and Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_30 min_ (-> 3:00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of monitoring solutions available. CoreOS, one of the driver organizations behind containerization, have provided a [Kubernetes Operator for Prometheus](https://github.com/coreos/prometheus-operator) - Operators are a relative recent, powerful tool for making Kubernetes more extensible, and allowing automated control loops, for example, to take care of dynamically-defined types of object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing this operator, which can be done with `helm`, adds in several new types of Kubernetes object: PrometheusRule and AlertingRule being two examples. The operator can then keep a cluster-hosted Prometheus server dynamically changing its configuration as those are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional Helm chart, [kube-prometheus](https://github.com/coreos/prometheus-operator/tree/master/helm/kube-prometheus) builds on this to provide live feeds of Pod, Service, Node resource usage, and alerting based off that. We have implemented a basic monitoring chart that adds support for Laravel failed job and exception tracking and alerts. While some of this can be done through the framework, this ensures that metrics and alerting can be managed centrally, and that individual, scaled out web-serving or queue processes are not responsible for contacting external APIs - rather they feed it back internally to be grouped, rate-managed, etc. in a standard way with the rest of the infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log aggregation (fluentbit, fluentd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the deployment, we create fluent-bit DaemonSets - these are essentially Deployments that run one Pod on each Node (VM). Gathering logs is a perfect application for them. Fluent-bit is a reimplementation in C of a lot of Fluentd's functionality. Fluent-bit can gather logs from the containers' stdout/stderr and send these to Fluentd, or to a number of other aggregators, such as Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                             READY     STATUS      RESTARTS   AGE\n",
      "buckram-fluentd-79b748589f-bskhx                 1/1       Running     0          48m\n",
      "buckram-laravel-nginx-6ddb575b85-w86kv           1/1       Running     0          48m\n",
      "buckram-laravel-phpfpm-1538609220-khvn2          0/1       Completed   0          2m\n",
      "buckram-laravel-phpfpm-1538609280-xz5kz          0/1       Completed   0          1m\n",
      "buckram-laravel-phpfpm-1538609340-vjcxg          0/1       Completed   0          58s\n",
      "buckram-laravel-phpfpm-1538609400-x6cb8          0/1       Completed   0          7s\n",
      "buckram-laravel-phpfpm-587d4c6fd8-cm59n          1/1       Running     0          29m\n",
      "buckram-laravel-phpfpm-worker-7dd798f458-mgz6b   1/1       Running     0          37m\n",
      "buckram-postgresql-0                             1/1       Running     0          48m\n",
      "buckram-redis-0                                  1/1       Running     0          48m\n",
      "fluent-bit-2z978                                 1/1       Running     0          48m\n",
      "fluent-bit-jkmbr                                 1/1       Running     0          48m\n",
      "fluent-bit-pd5pb                                 1/1       Running     0          48m\n",
      "laravel-job-1538607998-n94kw                     0/1       Completed   0          23m\n",
      "tiller-deploy-d8db78b5b-68spl                    1/1       Running     0          1h\n"
     ]
    }
   ],
   "source": [
    "kubectl get pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME   \tREVISION\tUPDATED                 \tSTATUS  \tCHART        \tNAMESPACE        \n",
      "buckram\t2       \tWed Oct  3 23:35:55 2018\tDEPLOYED\tbuckram-0.0.2\tscotlandphp-XXXXX\n"
     ]
    }
   ],
   "source": [
    "helm list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chown: /fluentd/etc/fluent.conf: Read-only file system\n",
      "2018-10-03 23:54:23 +0000 [info]: parsing config file is succeeded path=\"/fluentd/etc/fluent.conf\"\n",
      "2018-10-03 23:54:23 +0000 [info]: using configuration file: <ROOT>\n",
      "  <source>\n",
      "    @type forward\n",
      "    @id input1\n",
      "    @label @mainstream\n",
      "    port 24284\n",
      "  </source>\n",
      "  <label @mainstream>\n",
      "    <match kube.var.log.containers.**_kube-system_**>\n",
      "      @type null\n",
      "    </match>\n",
      "    <match>\n",
      "      @type file\n",
      "      path \"/fluentd/log/myapp\"\n",
      "      time_slice_format %Y%m%d%H\n",
      "      <buffer time>\n",
      "        timekey 3600\n",
      "        path /fluentd/log/myapp\n",
      "      </buffer>\n",
      "    </match>\n",
      "  </label>\n",
      "</ROOT>\n",
      "2018-10-03 23:54:23 +0000 [info]: starting fluentd-1.2.5 pid=6 ruby=\"2.4.4\"\n",
      "2018-10-03 23:54:23 +0000 [info]: spawn command to main:  cmdline=[\"/usr/bin/ruby\", \"-Eascii-8bit:ascii-8bit\", \"/usr/bin/fluentd\", \"-c\", \"/fluentd/etc/fluent.conf\", \"-p\", \"/fluentd/plugins\", \"--under-supervisor\"]\n",
      "2018-10-03 23:54:24 +0000 [info]: gem 'fluentd' version '1.2.5'\n",
      "2018-10-03 23:54:24 +0000 [info]: adding match in @mainstream pattern=\"kube.var.log.containers.**_kube-system_**\" type=\"null\"\n",
      "2018-10-03 23:54:24 +0000 [info]: adding match in @mainstream pattern=\"**\" type=\"file\"\n",
      "2018-10-03 23:54:24 +0000 [info]: adding source type=\"forward\"\n",
      "2018-10-03 23:54:24 +0000 [info]: #0 starting fluentd worker pid=16 ppid=6 worker=0\n",
      "2018-10-03 23:54:24 +0000 [info]: #0 [input1] listening port port=24284 bind=\"0.0.0.0\"\n",
      "2018-10-03 23:54:24 +0000 [info]: #0 fluentd worker is now running worker=0\n"
     ]
    }
   ],
   "source": [
    "kubectl logs $(kubectl get pods --selector=app=buckram-fluentd -o=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Autoscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to scale the number of deployed Pods automatically, using a HorizontalPodAutoscaler object, which responds to [predefined or custom metrics](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/). This is simplest to set up for CPU requests, but can work off, for example, [Prometheus metrics](https://github.com/directxman12/k8s-prometheus-adapter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, [Cluster Autoscaling](https://github.com/kubernetes/autoscaler) (where the number of Nodes changes) is cloud provider dependent. This is well-established especially for GKE, but also available for other Kubernetes providers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minikube\n",
    "\n",
    "(time permitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "minikube start\n",
    "[wait]\n",
    "kubectl get nodes\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will show you one node - the VM that is running Kubernetes, and all that is on it. In normal usage, you would have a larger set of nodes - many setups will have a pool of nodes for masters, usually high in CPU resources, and a pool of nodes, perhaps smaller and more plentiful for granular horizontal scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you enjoyed this workshop and am looking forward to feedback!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Follow-up course"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
